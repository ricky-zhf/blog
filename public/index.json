[{"categories":["go"],"content":"Unicode\u0026UTF-8 unicode 是统一所有语言的一套字符集(类似于字典)。utf-8是基于unicode编码的一种节约字节的编码。 UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间。但是两者并不完全相等，例如unicode一个中文字符占2个字节，而UTF-8一个中文字符占3个字节。既从unicode到utf-8并不是直接的对应，而是要过一些算法和规则来转换。 简而言之，在内存里统一使用unicode，记录到硬盘或者编辑文本的时候都转换成了utf8。 ps: ASCII 也是常用的英文单词和符号的小字符集，所以ASCII和Unicode 一样，是一种字符集。 ","date":"2023-03-02","objectID":"/posts/go/%E5%AD%97%E7%AC%A6%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/:1:0","tags":["go"],"title":"字符和字符串","uri":"/posts/go/%E5%AD%97%E7%AC%A6%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"categories":["go"],"content":"Byte \u0026 Rune Go严格意义上没有char类型，字符只是整数的特殊用例。在 Go 中，用于表示字符的 byte 和 rune 类型都是整型的别名： byte类型：长度为 1 个字节，用于表示 ASCII 字符。所以byte类型只能表示英文和部分符号。 rune类型：长度为 4 个字节，用于表示以 UTF-8 编码的 Unicode 码点。Unicode 从 0 开始，为每个符号指定一个编号，这叫做「码点」（code point）。 //byte是uint8的别名，等同于uint8，可以用于区分字节值和8位无符号整数值。 type byte = uint8 //rune是int32的别名，等同于int32，可以用于区分字符值和整数值。 type rune = int32 在go中，需要用单引号来声明字符，这点与其他语言一样。声明的类型可以为byte或者rune。但如果在声明一个字符变量时没有指明类型，Go 会默认它是 rune 类型： 因为 byte 实质上是整型 uint8，所以可以直接转成整型值，rune一样。在格式化说明符中我们使用 %c 表示字符，%d 表示整型： var byteC byte = 'A' fmt.Printf(\"字符 %c 的类型为 %T 整型为%v\\n\", byteC, byteC, byteC) //字符 j 的类型为 uint8 整型为106 var runeC rune = 'A' fmt.Printf(\"字符 %c 的类型为 %T 整型为%v\\n\", runeC, runeC, runeC) //字符 J 的类型为 int32 整型为74 之所以需要两个变量主要是为了适配UTF-8的编码方式。 byte 占用一个字节，因此它可以用于表示 ASCII 字符。但是UTF-8 的长度并不固定，字符长度从 1 个字节到 4 个字节不等。byte 显然不擅长这样的表示，因为解析的时候无法实时确定处理的 每个UTF-8 字符究竟占了几个字节。因此，如果堆中文字符串按照字节长度进行截取会出现乱码。 testString := \"你好，世界\" fmt.Println(testString[:2]) // 输出乱码�，因为截取了前两个字节 fmt.Println(testString[:3]) // 输出「你」，一个中文字符由三个字节表示 rune 可以解决该问题。利用 []rune() 将字符串转为 Unicode 码点再进行截取，这样就无需考虑字符串中含有 UTF-8 字符的情况了： testString := \"你好，世界\" fmt.Println(string([]rune(testString)[:2])) // 输出：「你好」 ","date":"2023-03-02","objectID":"/posts/go/%E5%AD%97%E7%AC%A6%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/:2:0","tags":["go"],"title":"字符和字符串","uri":"/posts/go/%E5%AD%97%E7%AC%A6%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"categories":["go"],"content":"遍历字符串 在go中，字符串使用utf-8进行编码(1-4为变长编码)，用len获取字符串长度获取到的是的字节长度，所以通过下标索引遍历字符串是以字节为基本单位的。 func main() { testString := \"hi,世界\" //len fmt.Println(len(testString)) //9 2*3+3 : 2个中文字符加3个英文字符 fmt.Println(utf8.RuneCountInString(testString)) //5 //下标遍历 for i := 0; i \u003c len(testString); i++ { //通过s[i]取出来的c是unit8类型, 既byte c := testString[i] fmt.Printf(\"下标: %v, 原值: %v, 用%%c取的值: %c\\n\", i, c, c) } /* 下标: 0, 原值: 104, 用%c取的值: h 下标: 1, 原值: 105, 用%c取的值: i 下标: 2, 原值: 44, 用%c取的值: , 下标: 3, 原值: 228, 用%c取的值: ä 下标: 4, 原值: 184, 用%c取的值: ¸ 下标: 5, 原值: 150, 用%c取的值: 下标: 6, 原值: 231, 用%c取的值: ç 下标: 7, 原值: 149, 用%c取的值: 下标: 8, 原值: 140, 用%c取的值: */ //range遍历 for i, c := range testString { // range s后，得到的c是int32位类型, 既rune fmt.Printf(\"下标: %v, 原值: %v, 用%%c取的值: %c\\n\", i, c, c) } /* 下标: 0, 原值: 104, 用%c取的值: h 下标: 1, 原值: 105, 用%c取的值: i 下标: 2, 原值: 44, 用%c取的值: , 下标: 3, 原值: 19990, 用%c取的值: 世 下标: 6, 原值: 30028, 用%c取的值: 界 */ //修改英文部分，string具有不可修改特性，如果修改bs[1]后直接打印testString会发现数据并没有改变。 bs := []byte(testString) bs[1] = 'K' testString = string(bs) fmt.Println(testString)//hK,世界 //修改中文 runes := []rune(testString) runes[0] = '我' testString = string(runes) fmt.Println(testString)//我K,世界 } ","date":"2023-03-02","objectID":"/posts/go/%E5%AD%97%E7%AC%A6%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/:3:0","tags":["go"],"title":"字符和字符串","uri":"/posts/go/%E5%AD%97%E7%AC%A6%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"categories":["middleware"],"content":"事务消息 这里RocketMQ采用了2PC的思想来实现了提交事务消息，同时增加一个补偿逻辑来处理二阶段超时或者失败的消息，如下图所示。 ","date":"2023-02-27","objectID":"/posts/middleware/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:1:0","tags":["mq"],"title":"rocketmq事务消息","uri":"/posts/middleware/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["middleware"],"content":"消息流程 发送半消息 服务端回应消息写入结果 根据写入结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见）。 ","date":"2023-02-27","objectID":"/posts/middleware/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:1:1","tags":["mq"],"title":"rocketmq事务消息","uri":"/posts/middleware/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["middleware"],"content":"补偿流程 补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。 对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查” Producer收到回查消息，检查回查消息对应的本地事务的状态 根据本地事务状态，重新Commit或者Rollback ","date":"2023-02-27","objectID":"/posts/middleware/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:1:2","tags":["mq"],"title":"rocketmq事务消息","uri":"/posts/middleware/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["middleware"],"content":"消息设计 1.事务消息在一阶段对用户不可见 在RocketMQ事务消息的主要流程中，一阶段的消息如何对用户不可见。其中，事务消息相对普通消息最大的特点就是一阶段发送的消息对用户是不可见的。那么，如何做到写入消息但是对用户不可见呢？RocketMQ事务消息的做法是：如果消息是half消息，将备份原消息的主题与消息消费队列，然后改变主题为RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费half类型的消息，然后RocketMQ会开启一个定时任务，从Topic为RMQ_SYS_TRANS_HALF_TOPIC中拉取消息进行回查，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。 在RocketMQ中，消息在服务端的存储结构如下，每条消息都会有对应的索引信息，Consumer通过ConsumeQueue这个二级索引来读取消息实体内容，其流程如下： RocketMQ的具体实现策略是：写入的如果事务消息，对消息的Topic和Queue等属性进行替换，同时将原来的Topic和Queue信息存储到消息的属性中，正因为消息主题被替换，故消息并不会转发到该原主题的消息消费队列，消费者无法感知消息的存在，不会消费。其实改变消息主题是RocketMQ的常用“套路”，回想一下延时消息的实现机制。 2.Commit和Rollback操作以及Op消息的引入 在完成一阶段写入一条对用户不可见的消息后，二阶段如果是Commit操作，则需要让消息对用户可见；如果是Rollback则需要撤销一阶段的消息。 由于 RocketMQ 的 appendOnly 特性，Broker通过 OP 消息实现标记删除。Broker 流程参考下图： Commit。Broker 写入 OP 消息，OP 消息的 body 指定 Commit 消息的 queueOffset，标记之前 Half 消息已被删除；同时，Broker 读取原 Half 消息，把 Topic 还原，重新写入 CommitLog，消费者则可以拉取消费； Rollback。Broker 同样写入 OP 消息，流程和 Commit 一样。但后续不会读取和还原 Half 消息。这样消费者就不会消费到该消息。 3.Op消息的存储和对应关系 RocketMQ将Op消息写入到全局一个特定的Topic中。这个Topic是一个内部的Topic（像Half消息的Topic一样），不会被用户消费。Op消息的内容为对应的Half消息的存储的Offset，这样通过Op消息能索引到Half消息进行后续的回查操作。 4.Half消息的索引构建 在执行二阶段Commit操作时，需要构建出Half消息的索引。一阶段的Half消息由于是写到一个特殊的Topic，所以二阶段构建索引时需要读取出Half消息，并将Topic和Queue替换成真正的目标的Topic和Queue，之后通过一次普通消息的写入操作来生成一条对用户可见的消息。所以RocketMQ事务消息二阶段其实是利用了一阶段存储的消息的内容，在二阶段时恢复出一条完整的普通消息，然后走一遍消息写入流程。 5.如何处理二阶段失败的消息？ 如果在RocketMQ事务消息的二阶段过程中失败了，例如在做Commit操作时，出现网络问题导致Commit失败，那么需要通过一定的策略使这条消息最终被Commit。 RocketMQ采用了一种补偿机制，称为“回查”。Broker通过异步线程定期执行(默认30s)，针对这些确实OP消息的办消息进行回查。起主要是将消息发送到对应的Producer端（同一个Group的Producer），由Producer根据消息来检查本地事务的状态，进而执行Commit或者Rollback。Broker端通过对比Half消息和OP消息进行事务消息的回查并且推进CheckPoint（记录那些事务消息的状态是确定的）。 值得注意的是，rocketmq并不会无休止的的信息事务状态回查，默认回查15次，如果15次回查还是无法得知事务状态，rocketmq默认回滚该消息。 ","date":"2023-02-27","objectID":"/posts/middleware/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/:1:3","tags":["mq"],"title":"rocketmq事务消息","uri":"/posts/middleware/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["go"],"content":"CSP Go 语言中最常见的、也是经常被人提及的设计模式就是：不要通过共享内存的方式进行通信，而是应该通过通信的方式共享内存。在很多主流的编程语言中，多个线程传递数据的方式一般都是共享内存，为了解决线程竞争，我们需要限制同一时间能够读写这些变量的线程数量。 虽然我们在 Go 语言中也能使用共享内存加互斥锁进行通信，但是 Go 语言提供了一种不同的并发模型，即通信顺序进程（Communicating sequential processes，CSP）。Goroutine 和 Channel 分别对应 CSP 中的实体和传递信息的媒介，Goroutine 之间会通过 Channel 传递数据。Go语言中的channel是一种特殊的类型，一个先进先出的队列。每一个通道都只传输一个具体类型，也就是声明channel的时候需要为其指定元素类型。 目前Go中的channel还是一个有锁的先进先出队列。但是社区也在讨论无锁的实现方式。 通过通信的方式来共享内存，说成人话就是Goroutine A和Goroutine B建立了管道C，通过管道获取和接受的方式来共享变量。例子可以参考：https://qcrao91.gitbook.io/go/channel/channel-fa-song-he-jie-shou-yuan-su-de-ben-zhi-shi-shi-mo ","date":"2023-02-19","objectID":"/posts/go/channel/:1:0","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"数据结构 type hchan struct { qcount uint //当前缓冲中元素个数 dataqsiz uint //循环数组的长度 buf unsafe.Pointer //指向缓冲区内存，这块内存空间可容纳`dataqsize`个元素 elemsize uint16 //当前 Channel 能够收发的元素大小 closed uint32 elemtype *_type //当前 Channel 能够收发的元素类型 sendx uint // 缓冲区中下一个元素写入时的位置 recvx uint // 缓冲区中下一个被读取的元素的位置 recvq waitq // 当前 Channel 由于缓冲区空间不足而阻塞导致等待接受的Goroutine 队列 sendq waitq // 当前 Channel 由于缓冲区空间不足而阻塞导致等待发送的Goroutine 队列 lock mutex //保证每个读 channel 或写 channel 的操作都是原子的。 } channel是一种类型，一种引用类型。声明通道类型的格式如下： var 变量 chan 元素类型 -- var ch1 chan int // 声明一个传递整型的通道 var ch2 chan bool // 声明一个传递布尔型的通道 var ch3 chan []int // 声明一个传递int切片的通道 通道是引用类型，通道类型的空值是nil。声明的通道后需要使用make函数初始化之后才能使用。 make(chan 元素类型, [缓冲大小]) //go语言中需要make的 slice map channel 缓冲大小可填可不填。 ","date":"2023-02-19","objectID":"/posts/go/channel/:2:0","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"缓冲区 缓冲区底层是一个循环数组，工作机制类似于环形队列： 环形队列使得我们可以保证缓冲区有序，并且不需要在每次取出元素时对缓冲区重新排序。当缓冲区满了时，向缓冲区添加元素的协程将被加入sender链表中，并且切换到等待状态。之后，当程序读取缓冲区时，recvx位置的元素将被返回，等待状态的协程将恢复执行，它要发送的值将被存入缓冲区。这使得 channel 能够保证先进先出的特性。 对于channel，有误缓冲区的场景下进行读写操作会有不同的结果： 向一个无缓冲区的channel发送数据，会阻塞 ； 从一个无缓冲区的channel 接收数据，会阻塞； 向一个已经关闭的 channel 发送数据(无论是否有缓冲区)，会引起 panic ； 从一个已经关闭的 channel 接收数据，如果缓冲区为空(无论是原本就是无缓冲区还是缓冲区的值读完了)，则返回一个零值。否则返回缓冲区中的值； 对于缓冲区的读写问题有一个口诀(参考)：空读写阻塞，写关闭异常，读关闭空零。 ","date":"2023-02-19","objectID":"/posts/go/channel/:3:0","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"无缓冲通道 无缓冲的通道又称为阻塞的通道。 func main() { ch := make(chan int) ch \u003c- 10 fmt.Println(\"发送成功\") } 上面这段代码能够通过编译，但是执行的时会出现死锁错误，即程序被挂起导致死锁。因为无缓冲的通道只有在接收方准备就绪后才能发送值给该管道，在此之前则一直处于阻塞状态。因此上面的代码会一直阻塞在第三行。同理，如果对一个无缓冲通道执行接收操作时，没有任何向通道中发送值的操作那么也会导致接收操作阻塞。 使用无缓冲通道进行通信将导致发送和接收的goroutine同步化。因此，无缓冲通道也被称为同步通道。 注意，上述的死锁一般只出现在主协程中，即如果主协程只对某个channel发送或者接受值，而没有其他协程做对应操作，则会发生死锁阻塞问题。但是如果是子协程则不会出现这个问题，如下面的程序会正常输出end，而不会发生死锁。 func main() { ch := make(chan string) go func() { fmt.Println(\u003c-ch) }() fmt.Println(\"end\") } 像如下代码能正常编译执行，但是什么都没打印就结束。因为进程结束，导致所有流程终止。 func main() { ch := make(chan string) go func() { fmt.Println(\u003c-ch) }() ch \u003c- \"aa\" } 简而言之，对于无缓冲通道的分析主要就是： 在通道close前，检查各阶段通道的读写操作是否能一一对应，以此来判断是否产生死锁问题； close后，就是写关闭异常，读关闭空零的问题。 ","date":"2023-02-19","objectID":"/posts/go/channel/:3:1","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"有缓冲通道 如果不想产生阻塞，则可以使用有缓冲通道。如下代码能正常输入aa。 func main() { ch := make(chan string, 1) ch \u003c- \"aa\" fmt.Println(\u003c-ch) } ","date":"2023-02-19","objectID":"/posts/go/channel/:3:2","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"channel操作 channel有三种操作，send，receive, close。 发送和接收都使用\u003c-符号 ch := make(chan int) ch \u003c- 10//赋值语句右边赋值给左边，将10赋值给ch通道，就是发送10给ch通道。 x := \u003c- ch//赋值语句右边赋值给左边, x从ch通道接受一个值。 //\u003c-ch 从ch中接收值，忽略结果 close(ch) 关于关闭通道需要注意的事情是，只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。通道是可以被垃圾回收机制回收的，它和关闭文件是不一样的，在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。 一般而言需要总是先接收后发送，并由发送端来关闭。 对于接收值还可以通过下面这种方式： value, ok := \u003c- ch value：从通道中取出的值。 ok：通道关闭为 false，否则为true。 如果需要循环接受缓冲区的值，有3种方式。 ","date":"2023-02-19","objectID":"/posts/go/channel/:4:0","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"for for循环和下面的range循环在无缓冲管道的场景下都需要注意两个点： 发送方需要关闭管道。否则接收方通过for循环读取时会报死锁错误，因为不关闭管道，当接收方读完管道内数据后，会一直阻塞。因为第四行的for循环执行完了，但是接收方继续for循环，在11行时由于没有发送方所以死锁。 接收方需要判断管道是否关闭然后选择是否跳出for循环。否则当发送方发完数据并关闭管道后，接收方会一直读出零值。 func main() { c := make(chan int) go func() { for i := 0; i \u003c 3; i++ { c \u003c- i fmt.Println(\"通道写入\", i) } close(c) }() for { i, ok := \u003c-c if !ok { break } fmt.Println(\"通道读出:\", i) } fmt.Println(\"Finished\") } /* 通道写入 0 通道读出: 0 通道读出: 1 通道写入 1 通道写入 2 通道读出: 2 Finished*/ ","date":"2023-02-19","objectID":"/posts/go/channel/:4:1","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"for range for range会在管道关闭后自动退出，而不需要像for循环那样做判断。 func main() { c := make(chan int) go func() { for i := 0; i \u003c 5; i++ { c \u003c- i fmt.Println(\"通道写入\", i) } close(c) }() for i := range c { fmt.Println(\"通道读出:\", i) } fmt.Println(\"Finished\") } /*通道写入 0 通道读出: 0 通道读出: 1 通道写入 1 通道写入 2 通道读出: 2 Finished*/ ","date":"2023-02-19","objectID":"/posts/go/channel/:4:2","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"select 因此对于channel的处理，更推荐使用select。Go 语言中的 select语句用于对一组case语句进行选择，并执行对应的代码。类似switch，但是select语句中所有case中的表达式都必须是channel的发送或接收操作。Select 语句具有以下几个特点： select 不存在任何的 case：永久阻塞当前 goroutine select 只存在一个 case：阻塞的发送/接收 select 存在多个 case：随机选择一个满足条件的case执行 select 存在 default，其他case都不满足时：执行default语句中的代码 先看个栗子： func main() { ch := make(chan int, 1) for i := 1; i \u003c= 10; i++ { select { case x := \u003c-ch: fmt.Println(x) case ch \u003c- i: } } } 首先是创建了一个缓冲区大小为1的通道 ch，进入 for 循环后： 第一次循环时 i = 1，select 语句中包含两个 case 分支，此时由于通道中没有值可以接收，所以x := \u003c-ch 这个 case 分支不满足，而ch \u003c- i这个分支可以执行，会把1发送到通道中，结束本次 for 循环； 第二次 for 循环时，i = 2，由于通道缓冲区已满，所以ch \u003c- i这个分支不满足，而x := \u003c-ch这个分支可以执行，从通道接收值1并赋值给变量 x ，所以会在终端打印出 1； 后续的 for 循环以此类推会依次打印出3、5、7、9。 ","date":"2023-02-19","objectID":"/posts/go/channel/:4:3","tags":["go"],"title":"channel笔记","uri":"/posts/go/channel/"},{"categories":["go"],"content":"应用程序中的内存一般会分为堆和栈两个部分，程序要运行期间可以主动向堆内存申请内存空间，这些内存由内存分配器分配并由垃圾回收期回收。而栈内存一般由编译器自动分配和释放。其中主要存储函数局部变量、入参、返回值等数据，这些数据一般会随着函数一起创建和销毁。 ","date":"2023-02-11","objectID":"/posts/go/go%E6%A0%88%E5%86%85%E5%AD%98/:0:0","tags":["go"],"title":"go栈内存","uri":"/posts/go/go%E6%A0%88%E5%86%85%E5%AD%98/"},{"categories":["go"],"content":"栈结构 传统的程序虚拟空间分布如下： 对于传统程序而言，程序计数器的缺省值为0，当运行完当前指令则加1，因此代码段数据段文件自然从地地址向搞高地址进行分配。heap从低地址向高地址扩展，是因为做内存管理相对要简单些。 而为了避免栈空间和堆空间、代码段等冲突，并最大利用地址空间，就会选择把栈底设置在高地址区间，然后让栈向下增长。这样栈底地址是固定的（高地址），只需要移动栈顶指针即可实现栈的扩展。如果将栈从地址开始分配，则栈底地址并不固定（可能面临堆空间快扩容的场景），此时就可能需要将整个栈在内存中移动。因此对于栈而言，是由高地址向低地址进行分配。 所以对于程序空间中的栈而言，是一个倒着的栈，栈基在上面（内存高地址），栈顶在下面（内存地地址）。 ","date":"2023-02-11","objectID":"/posts/go/go%E6%A0%88%E5%86%85%E5%AD%98/:1:0","tags":["go"],"title":"go栈内存","uri":"/posts/go/go%E6%A0%88%E5%86%85%E5%AD%98/"},{"categories":["go"],"content":"Go栈内存空间 对于Go程序中的栈而言，也是由高地址向低地址进行分配，由一个个栈桢组成，当调用某个函数时，则将一个栈帧由栈顶压入栈。当被调函数执行完毕后，会则撤销当前函数对应的栈桢，也即出栈。对于栈桢而言，有两个包含 BP 和 SP 两个栈寄存器，它们分别存储了栈基地址和栈顶地址，两个地址之间的内容就是一个栈桢。 ","date":"2023-02-11","objectID":"/posts/go/go%E6%A0%88%E5%86%85%E5%AD%98/:2:0","tags":["go"],"title":"go栈内存","uri":"/posts/go/go%E6%A0%88%E5%86%85%E5%AD%98/"},{"categories":["go"],"content":"栈桢 Go 语言中函数栈帧布局由高到低（栈底到栈顶），以下面的代码为例，当程序运行到t函数第2行时如下： 调用方的栈基地址，用于函数返回后获得调用函数的栈帧基地址：main函数的栈基地址。 局部变量：a1， b1； 被调函数返回值：res1，res2； 被调用函数参数：a1，b1； 返回地址，保存被调用函数返回后的程序地址，即本函数调用被调用函数的下一条指令地址：res1++指令的地址。 tt的栈桢：就是重复上面5个部分了。 func t(a, b int) (int, int) { a1, b1 := a, b res1, res2:= tt(a1, b1) res1++ return res1, res2 } func tt(a, b int) (int, int) { res1, res2 := a + b, a - b return res1, res2 } func main() { i, j := t(1, 2) fmt.Println(i, j) } ","date":"2023-02-11","objectID":"/posts/go/go%E6%A0%88%E5%86%85%E5%AD%98/:3:0","tags":["go"],"title":"go栈内存","uri":"/posts/go/go%E6%A0%88%E5%86%85%E5%AD%98/"},{"categories":["middleware"],"content":"ConsumeQueue Consumer端订阅消息是需要通过ConsumeQueue这个消息消费的逻辑队列拿到一个索引，然后再从CommitLog里面读取真正的消息实体内容。RocketMQ 通过使用在一个 Topic 中配置多个队列并且每个队列维护每个消费者组的消费位置 实现了 主题模式/发布订阅模式 队列是消息队列中消息存储和传输的实际容器，也是消息队列RocketMQ版消息的最小存储单元。所有主题都是由多个队列组成，以此实现队列数量的水平拆分和队列内部的流式存储。生产者指定某个主题，向主题内发送消息，但实际消息发送到该主题下的某个队列中。消息队列RocketMQ版中通过修改队列数量，以此实现横向的水平扩容和缩容。 消息存储架构图中主要有下面三个跟消息存储相关的文件构成。 CommitLog：消息主体以及元数据的存储主体； ConsumerQueue：消息消费索引，引入的目的主要是提高消息消费的性能。由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件，根据topic检索消息是非常低效的。Consumer可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值； IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。 在上面的RocketMQ的消息存储整体架构图中可以看出，RocketMQ采用的是混合型的存储结构： 即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。 RocketMQ的混合型存储结构(多个Topic的消息实体内容都存储于一个CommitLog中)针对Producer和Consumer分别采用了数据和索引部分相分离的存储结构，Producer发送消息至Broker端，然后Broker端使用同步或者异步的方式对消息刷盘持久化，保存至CommitLog中。只要消息被刷盘持久化至磁盘文件CommitLog中，那么Producer发送的消息就不会丢失。正因为如此，Consumer也就肯定有机会去消费这条消息。当无法拉取到消息后，可以等下一次消息拉取，同时服务端也支持长轮询模式，如果一个消息拉取请求未拉取到消息，Broker允许等待30s的时间，只要这段时间内有新消息到达，将直接返回给消费端。这里RocketMQ的具体做法是，使用Broker端的后台服务线程—ReputMessageService不停地分发请求并异步构建ConsumeQueue（逻辑消费队列）和IndexFile（索引文件）数据。 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:1:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"Consumer和Queue Consumer和queue会优先平均分配， 如果Consumer少于queue的个数，则会存在部分Consumer消费多个queue的情况。 如果Consumer等于queue的个数，那就是一个Consumer消费一个queue。 如果Consumer个数大于queue的个数，那么会有部分Consumer空余出来，白白的浪费了。 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:2:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"Offset ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:3:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"Min/Max Offset 消息队列RocketMQ版定义队列中最早一条消息的位点为最小消息位点（MinOffset）；最新一条消息的位点为最大消息位点（MaxOffset）。虽然消息队列逻辑上是无限存储，但由于服务端物理节点的存储空间有限，消息队列RocketMQ版会滚动删除队列中存储最早的消息。因此，消息的最小消费位点和最大消费位点会一直递增变化。 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:3:1","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"Consumer Offset 消息队列RocketMQ版领域模型为发布订阅模式，每个主题的队列都可以被多个消费者分组订阅。若某条消息被某个消费者消费后直接被删除，则其他订阅了该主题的消费者将无法消费该消息。因此，消息队列RocketMQ版通过消费位点管理消息的消费进度。每条消息被某个消费者消费完成后不会立即在队列中删除，消息队会基于每个消费者分组在每个队列上维护一份消费记录，该记录指定消费者分组消费该队列时，消费过的最新一条消息的位点，即消费位点。 当消费者客户端离线，又再次重新上线时，会严格按照服务端保存的消费进度继续处理消息。如果服务端保存的历史位点信息已过期被删除，此时消费位点向前移动至服务端存储的最小位点。 在RocketMQ 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用Offset 来访问，Offset 为 java long 类型，64 位，理论上在 100年内不会溢出，所以认为是长度无限。也可以认为 Message Queue 是一个长度无限的数组，Offset 就是下标。 一个主题存在多个队列，生产者每次生产消息后向指定主题中的某个队列发送消息。在集群消费模式下，一个消费者集群的多个消费者共同消费一个Topic的多个队列，一个队列只会被一个消费者消费，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。一般来讲要控制消费者组中的消费者个数和主题中队列个数相同 ，当然也可以消费者个数小于队列个数，只不过不太建议。 在发布订阅模式中一般会涉及到多个消费者组，而每个消费者组在每个队列中的消费位置都是不同的。如果此时有多个消费者组，那么消息被一个消费者组消费完之后是不会删除的（因为一个Topic可以被多个消费者订阅，那么其它消费者组也需要），它仅仅是为每个消费者组维护一个 消费位移(offset) ，每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了。 简而言之就是： 每个消费者组消费Topic下的所有队列，该组中每个消费者可以消费多个消息队列，但是每个消息队列同一时间只能被同一消费组内的一个消费者消费； Consumer Offset初始值 消费位点初始值指的是消费者分组首次启动消费者消费消息时，服务端保存的消费位点的初始值。 消息队列RocketMQ版定义消费位点的初始值为消费者首次获取消息时，该时刻队列中的最大消息位点。相当于消费者将从队列中最新的消息开始消费。 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:3:2","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"先总结下 一个Broker里有一个CommitLog； 一个CommitLog里可以存多个Topic的消息； 一个Topic可以有多个consumer queue。一个topic可以对应多个消费者组，反之亦然； 同一条队列可以被不同消费者组的消费者消费。同样，消费者也可以消费不同topic的下的队列 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:4:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"页存储和内存映射 页缓存（PageCache)是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因就是由于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。对于数据的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于数据的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取。 在RocketMQ中，ConsumeQueue逻辑消费队列存储的数据较少，并且是顺序读取，在page cache机制的预读取作用下，Consume Queue文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。 而对于CommitLog消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取，严重影响性能。如果选择合适的系统IO调度算法，比如设置调度算法为“Deadline”（此时块存储采用SSD的话），随机读的性能也会有所提升。 另外，RocketMQ主要通过MappedByteBuffer对文件进行读写操作。其中，利用了NIO中的FileChannel模型将磁盘上的物理文件直接映射到用户态的内存地址中（这种mmap的方式减少了传统IO将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率。正因为需要使用内存映射机制，故RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存。 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:5:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"消息刷盘 (1) 同步刷盘：如上图所示，只有在消息真正持久化至磁盘后RocketMQ的Broker端才会真正返回给Producer端一个成功的ACK响应。同步刷盘对MQ消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般适用于金融业务应用该模式较多。 (2) 异步刷盘：能够充分利用OS的PageCache的优势，只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了MQ的性能和吞吐量。 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:6:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"通信方式 在RocketMQ消息队列中支持通信的方式主要有同步(sync)、异步(async)、单向(oneway) 三种。其中“单向”通信模式相对简单，一般用在发送心跳包场景下，无需关注其Response。 RocketMQ消息队列集群主要包括NameServer、Broker(Master/Slave)、Producer、Consumer4个角色，基本通讯流程如下： (1) Broker启动后需要完成一次将自己注册至NameServer的操作；随后每隔30s时间定时向NameServer上报Topic路由信息。 (2) 消息生产者Producer作为客户端发送消息时候，需要根据消息的Topic从本地缓存的TopicPublishInfoTable获取路由信息。如果没有则更新路由信息会从NameServer上重新拉取，同时Producer会默认每隔30s向NameServer拉取一次路由信息。 (3) 消息生产者Producer根据2）中获取的路由信息选择一个队列（MessageQueue）进行消息发送；Broker作为消息的接收者接收消息并落盘存储。 (4) 消息消费者Consumer根据2）中获取的路由信息，并再完成客户端的负载均衡后，选择其中的某一个或者某几个消息队列来拉取消息并进行消费。 从上面1）~3）中可以看出在消息生产者，Broker和NameServer之间都会发生通信（这里只说了MQ的部分通信），因此如何设计一个良好的网络通信模块在MQ中至关重要，它将决定RocketMQ集群整体的消息传输能力与最终的性能。 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:7:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"主从同步 两种类型： 同步双写 SYNC_MASTER 异步复制 ASYNC_MASTER 如果是SYNC_MASTER模式，消息发送者将消息刷写到磁盘后，需要继续等待新数据被传输到从服务器，从服务器数据的复制是在另外一个线程HAConnection中去拉取，所以消息发送者在这里需要等待数据传输的结果，GroupTransferService就是实现该功能。 而ASYNC_MASTER模式，消息在master写入成功，即会返回成功，无需等待slave。 ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:8:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"参考 https://github.com/apache/rocketmq/blob/master/docs/cn/design.md ","date":"2023-02-11","objectID":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/:9:0","tags":["mq"],"title":"rocketmq存储设计","uri":"/posts/middleware/rocketmq%E5%AD%98%E5%82%A8/"},{"categories":["middleware"],"content":"架构 主要有四大核心组成部分：NameServer、Broker、Producer以及Consumer四部分。 RocketMQ架构上主要分为四部分，如上图所示： Producer：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。 Consumer：消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。 NameServer：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能 Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。 心跳检测机制，检查Broker是否还存活； BrokerServer：Broker主要负责消息的存储、投递和查询以及服务高可用保证。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/:1:0","tags":["mq"],"title":"rocketmq架构","uri":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/"},{"categories":["middleware"],"content":"NamerServer 可以理解为一个注册中心，==主要用来保存整个Broker集群的路由信息和心跳检测。生产者和消费者通过name server找到各topic对应的broker ip列表==。多个name server组成集群，但是没有信息交互。 路由信息：==Broker在启动时会向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。==当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer和Consumer仍然可以动态感知Broker的路由的信息。==Producer 在发送消息前会根据 Topic 到 NameServer 获取到 Broker 的路由信息，Consumer 也会定时获取 Topic 的路由信息。== 心跳检测； 但有一点需要注意，Broker向NameServer发心跳时， 会带上当前自己所负责的所有Topic信息，如果Topic个数太多（万级别），会导致一次心跳中，就Topic的数据就几十M，网络情况差的话， 网络传输失败，心跳失败，导致NameServer误认为Broker心跳失败。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/:1:1","tags":["mq"],"title":"rocketmq架构","uri":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/"},{"categories":["middleware"],"content":"Broker 核心的一个角色，==Broker主要负责消息的存储、投递和查询以及服务高可用保证==。在一个Broker集群中，相同的BrokerName可以称为一个Broker组，一个Broker组中, BrokerId为0的为主节点，其它的为从节点。BrokerName和BrokerId是可以在Broker启动时通过配置文件配置的。每个Broker组只存放一部分消息。每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。 Broker包含了以下几个重要子模块。 Remoting Module：整个Broker的实体，负责处理来自Client端的请求。 Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息。 Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。 Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/:1:2","tags":["mq"],"title":"rocketmq架构","uri":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/"},{"categories":["middleware"],"content":"Producer Producer由用户进行分布式部署，消息由Producer通过多种负载均衡模式发送到Broker集群，发送低延时，支持快速失败。 RocketMQ 提供了多种方式发送消息： 同步发送：同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。一般用于重要通知消息，例如重要通知邮件、营销短信。 异步发送：异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包，一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。 单向发送：单向发送是指只负责发送消息而不等待服务器回应且没有回调函数触发，适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。 顺序发送。 ​ ==生产者和主题的关系为多对多关系，即同一个生产者可以向多个主题发送消息，对于平台类场景如果需要发送消息到多个主题，并不需要创建多个生产者；同一个主题也可以接收多个生产者的消息，以此可以实现生产者性能的水平扩展和容灾。== ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/:1:3","tags":["mq"],"title":"rocketmq架构","uri":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/"},{"categories":["middleware"],"content":"Consumer 用来消费生产者消息的一方，==消费者必须关联一个指定的消费者分组==，以获取分组内统一定义的行为配置和消费状态。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/:1:4","tags":["mq"],"title":"rocketmq架构","uri":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/"},{"categories":["middleware"],"content":"Group 分为ProducerGroup，ConsumerGroup，代表某一类的生产者和消费者，一个组可以订阅多个Topic。 ProducerGroup代表同一类Producer的集合，这类Producer发送同一类消息且发送逻辑一致。如果发送的是事务消息且原始生产者在发送之后崩溃，则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消费。 ConsumerGroup代表同一类Consumer的集合，这类Consumer通常消费同一类消息且消费逻辑一致。消费者组使得在消息消费方面，实现负载均衡和容错的目标变得非常容易。要注意的是，消费者组的消费者实例必须订阅完全相同的Topic。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/:1:5","tags":["mq"],"title":"rocketmq架构","uri":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/"},{"categories":["middleware"],"content":"总览 NameServer是一个几乎无状态节点，可集群部署，==节点之间无任何信息同步。== Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。==每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。== 注意：当前RocketMQ版本在部署架构上支持一Master多Slave，==但只有BrokerId=1的从服务器才会参与消息的读负载。== Producer与NameServer集群中的==其中一个节点（随机选择）建立长连接==，定期从NameServer获取Topic路由信息，==并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。==Producer完全无状态，可集群部署。 Consumer与NameServer集群中的==其中一个节点（随机选择）建立长连接==，定期从NameServer获取Topic路由信息，==并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。==Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。 ==结合部署架构图，描述集群工作流程：== 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。 Broker启动，跟所有的NameServer保持长连接，定时(30s)发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。 Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，==并从NameServer中获取Topic路由信息并缓存到本地==(TopicPublishInfoTable)，发消息时==轮询==从Topic的队列列表中选择一个队列，==然后与队列所在的Broker建立长连接从而向Broker发消息。== Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。其中还会做负载均衡后，选择其中的某一个或者某几个消息队列来拉取消息并进行消费。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/:1:6","tags":["mq"],"title":"rocketmq架构","uri":"/posts/middleware/rocketmq%E6%9E%B6%E6%9E%84/"},{"categories":["middleware"],"content":"消费者组 RocketMQ中，订阅者的概念是通过消费组（Consumer Group）来体现的。 每个消费组都消费主题中的所有队列，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被Consumer Group1消费过，也会再给Consumer Group2消费。 消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费某条队列中的消息。默认情况，如果一条消息被消费者Consumer1消费了，那同组的其他消费者就不会再收到这条消息。 消费逻辑大致为： 每个消费者组消费Topic下的所有队列，该组中每个消息可以消费多个消息队列，但是每个消息队列同一时间只能被同一消费组内的一个消费者消费； 同一个Topic可以被多个消费者组消费，同一条队列可以被不同消费者组的消费者消费 在消息队列RocketMQ版领域模型中，同一条消息支持被多个消费者分组订阅，同时，对于每个消费者分组可以初始化多个消费者。您可以根据消费者分组和消费者的不同组合，实现以下两种不同的消费效果： 消费组间广播消费：如上图所示，每个消费者分组只初始化唯一一个消费者，每个消费者可消费到消费者分组内所有的消息，各消费者分组都订阅相同的消息，以此实现单客户端级别的广播一对多推送效果。该方式一般可用于网关推送、配置推送等场景。 消费组内共享消费：如上图所示，每个消费者分组下初始化了多个消费者，这些消费者共同分担消费者分组内的所有消息，实现消费者分组内流量的水平拆分和均衡负载。该方式一般可用于微服务解耦场景。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:1:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"消息获取 https://www.jianshu.com/p/70800fe967fd 一般消息消费的模式有两种方式： Push Consumer：消息由RocketMQ送至Consumer。 Pull Consumer：该类Consumer主动从RocketMQ拉取消息。目前仅TCP Java SDK支持该类Consumer。 这两种方式都有各自的缺点： 拉取：拉取的间隔不好确定，间隔太短没消息时会造成带宽浪费，间隔太长又会造成消息不能及时被消费 推送：「推送和速率难以适配消费速率」，推的太快，消费者消费不过来怎么办？推的太慢消息不能及时被消费 RocketMQ结合了两种模式(实质上还是pull)，Consumer发送拉取请求到Broker端，如果Broker有数据则返回，然后Consumer端再次拉取。如果Broker端没有数据，不立即返回，而是等待一段时间（例如5s）。 如果在等待的这段时间，有新消息到来，则激活consumer发送来hold的请求，立即将消息通过channel写入consumer客户，随后Consumer端再次拉取。 如果等待超时（例如5s），也会直接返回，不会将这个请求一直hold住，Consumer端再次拉取。 长轮询解决轮询带来的频繁请求服务端但是没有的问题一旦新的数据到了，那么消费者能立马就可以获取到新的数据，所以从效果上，有点像是push的感觉。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:2:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"消费模式 默认情况下就是集群消费，当使用集群消费模式时，消息队列RocketMQ版认为任意一条消息只需要被集群内的任意一个消费者处理即可。 当使用广播消费模式时，消息队列RocketMQ版会将每条消息推送给集群内所有的消费者，保证消息至少被每个消费者消费一次。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:3:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"消息处理 当拉取到消息后，消息会被放入msgTreeMap，其中key为消息的offset，value为消息实体。 另外还有一个重要的属性dropped，和重平衡相关，重平衡的时候会造成消息的重复消费。 msgCount（未消费消息总数）和msgSize（未消费消息大小）是和流控相关的。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:4:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"消息过滤 RocketMQ分布式消息队列的消息过滤方式有别于其它MQ中间件，是在Consumer端订阅消息时再做消息过滤的。RocketMQ这么做是在于其Producer端写入消息和Consumer端订阅消息采用分离存储的机制来实现的，Consumer端订阅消息是需要通过ConsumeQueue这个消息消费的逻辑队列拿到一个索引，然后再从CommitLog里面读取真正的消息实体内容，所以说到底也是还绕不开其存储结构。其ConsumeQueue的存储结构如下，可以看到其中有8个字节存储的Message Tag的哈希值，基于Tag的消息过滤正是基于这个字段值的。 主要支持如下2种的过滤方式 Tag过滤方式：Consumer端在订阅消息时除了指定Topic还可以指定TAG，如果一个消息有多个TAG，可以用||分隔。其中，Consumer端会将这个订阅请求构建成一个 SubscriptionData，发送一个Pull消息的请求给Broker端。Broker端从RocketMQ的文件存储层—Store读取数据之前，会用这些数据先构建一个MessageFilter，然后传给Store。Store从 ConsumeQueue读取到一条记录后，会用它记录的消息tag hash值去做过滤，由于在服务端只是根据hashcode进行判断，无法精确对tag原始字符串进行过滤，故在消息消费端拉取到消息后，还需要对消息的原始tag字符串进行比对，如果不同，则丢弃该消息，不进行消息消费。 SQL92的过滤方式：这种方式的大致做法和上面的Tag过滤方式一样，只是在Store层的具体过滤过程不太一样，真正的 SQL expression 的构建和执行由rocketmq-filter模块负责的。每次过滤都去执行SQL表达式会影响效率，所以RocketMQ使用了BloomFilter避免了每次都去执行。SQL92的表达式上下文为消息的属性。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:5:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"消费重试 https://help.aliyun.com/document_detail/440356.html 消费重试指的是，消费者在消费某条消息失败后，消息队列RocketMQ版服务端会根据重试策略重新消费该消息，超过一次定数后若还未消费成功，则该消息将不再继续重试，直接被发送到死信队列中。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:6:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"消息不丢失 消息可能在哪些阶段丢失呢？可能会在这三个阶段发生丢失：生产阶段、存储阶段、消费阶段。所以要从这三个阶段考虑： Producer 可以采取send()同步发消息，发送结果是同步感知的。发送失败后可以重试，设置重试次数，默认2次。 集群部署，比如发送失败了的原因可能是当前Broker宕机了，重试的时候会发送到其他Broker上。 Broker 同步刷盘和异步刷盘，不管哪种刷盘都可以保证消息一定存储在pagecache中（内存中），但是同步刷盘更可靠，它是Producer发送消息后等数据持久化到磁盘之后再返回响应给Producer。所以修改刷盘策略为同步刷盘，默认情况下是异步刷盘的。flushDiskType = SYNC_FLUSH Broker通过主从模式来保证高可用，Broker支持Master和Slave同步复制、Master和Slave异步复制模式，生产者的消息都是发送给Master，但是消费既可以从Master消费，也可以从Slave消费。同步复制模式可以保证即使Master宕机，消息肯定在Slave中有备份，保证了消息不会丢失。 Consumer Consumer保证消息成功消费的关键在于确认的时机，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。因为消息队列维护了消费的位置，逻辑执行失败了，没有确认，再去队列拉取消息，就还是之前的一条。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:7:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"重复消费 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:8:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"产生原因 MQ重复消费是指同一个应用的多个实例收到相同的消息，或者同一个实例收到多次相同的消息，若消费者逻辑未做幂等处理，就会造成重复消费。消息重复这个问题本质上是MQ设计上的at least once 还是exactly once的问题，消费者肯定想要exactly once，但MQ要保证消息投递的可靠性，对未ack的消息，会重复投递。 正常情况下在consumer真正消费完消息后应该发送ack，通知broker该消息已正常消费。当ack因为网络原因无法发送到broker，broker会认为此条消息没有被消费，此后会开启消息重投机制把消息再次投递到consumer。 在CLUSTERING集群消费模式下，消息在broker中会保证相同group的consumer消费一次，但是针对不同group的consumer会推送多次。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:8:1","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"解决办法 因此消费者端要自己保证消费的幂等性，方法如：消费者收到消息后，从消息中获取消息标识写入到Redis或数据库，当再次收到该消息时就不作处理。消息重复投递的场景，除重试外，很大一部分来自于负载均衡阶段，前一个监听Queue的消费实例拉取的消息未全部ack，新的消费实例监听到这个Queue重新拉取消息。 基本上解决办法有如下几种： 业务幂等，数据库乐观锁； 消息去重：这种方法，需要保证每条消息都有一个惟一的编号，通常是业务相关的，比如订单号，消费的记录需要落库，而且需要保证和消息确认这一步的原子性。 分布式锁； ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:8:2","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"消息堆积 Producer已经将消息发送到消息队列RocketMQ版的服务端，但由于Consumer消费能力有限，未能在短时间内将所有消息正确消费掉，此时在消息队列服务端保存着未被消费的消息，该状态即消息堆积。 消息堆积量=处理中消息量+已就绪消息量，具体的指标含义，可参考以下说明： 上图表示指定Topic的某一队列中各消息的状态。 处理中消息：在消费者客户端正在处理中但客户端还未返回消费成功响应的消息。 已就绪消息：消息在消息队列已就绪，可以被消费者消费的消息。已就绪消息量指标反映还未被消费者开始处理的消息规模。 已就绪消息的就绪时间： 普通消息：消息的存储时间。 定时/延时消息：定时或延时结束时间。 事务消息：事务提交时间。 已就绪消息的排队时间：最早一条就绪消息的就绪时间和当前时间差。 该指标反映了还未被处理的消息的延迟时间大小，对于时间敏感的业务来说是非常重要的度量指标。 示例：如上图所示，最早一条就绪消息M1的就绪时间为12:00:00，最后一条就绪消息M2的就绪时间为12:00:30。假设当前时间为12:00:50，则已就绪消息排队时间=当前时间－M1消息的就绪时间=50秒。 解决方案： 首先判断消息挤压的原因 如果是Producer太多而Consumer太少，且消息消费速度正常，则可以通过暂时上线多个Consumer来临时解决消息堆积问题； 如果当前Topic的Message Queue的数量小于或者等于消费者数量，这种情况，再扩容消费者就没什么用，就得考虑扩容Message Queue。 可以新建一个临时的Topic，临时的Topic多设置一些Message Queue， 然后先用一些消费者把消费的数据丢到临时的Topic，因为不用业务处理，只是转发一下消息，还是很快的。 扩容多台消费者去消费新的Topic里的数据。 消费完了之后，恢复原状。 ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:9:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["middleware"],"content":"参考 https://help.aliyun.com/document_detail/440186.html https://github.com/apache/rocketmq/blob/master/docs/cn/features.md#%E7%89%B9%E6%80%A7features ","date":"2023-02-09","objectID":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/:10:0","tags":["mq"],"title":"rocketmq消息消费","uri":"/posts/middleware/rocketmq%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"},{"categories":["go"],"content":"Goroutine ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:1:0","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"range陷阱 使用匿名函数的goroutine时，传入子goroutine的是k和v的指针，而不是值的备份;当goroutine执行时，才会读取地址内的数据值. func test1() { m := map[int]int { 1:1, 2:2, 3:3, } for k, v := range m { fmt.Printf(\"Start to range k:%v|v:%v\\n\", k, v) go func() { fmt.Printf(\"Go routine k:%v|v:%v\\n\", k, v) }() //time.Sleep(3 * time.Second) 如果这里放开，则会正常打印1 2 3，因为主循环等待3s足够协程获取当前k，v的值。 } time.Sleep(3 * time.Second) } /* Start to range k:1|v:1 Start to range k:2|v:2 Start to range k:3|v:3 Go routine k:3|v:3 Go routine k:3|v:3 Go routine k:3|v:3*/ 而正确的解决办法是带上参数。但是记住，协程运行顺序不确定，所以打印顺序也不一定是123。 go func(k, v int) { fmt.Printf(\"Go routine k:%v|v:%v\\n\", k, v) }(k, v) ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:1:1","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"指针 ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:2:0","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"遍历中取地址 func main() { arr := []Person{ Person{\"小明\"}, Person{\"小刚\"}, } var res []*Person for _, v := range arr { res = append(res, \u0026v) } // 遍历查看原数据集 for _, v := range arr{ fmt.Printf(\"v 指针 %p\\\\n\", \u0026v) fmt.Println(\"v 的值\", v) res = append(res, \u0026v) } fmt.Println(\"res=\", res) // 遍历查看结果集 for _, person := range res{ fmt.Println(\"name--\u003e:\", person.name) } } --遍历查看原数据集 v 指针 0xc0001101e0 v 的值 {小明} v 指针 0xc0001101e0 v 的值 {小刚} res=[0xc0001101e0 0xc0001101e0] --遍历查看结果集 name--\u003e: 小刚 name--\u003e: 小刚 可以得出结论，用for range遍历时，v这个地方一直使用同一个地址去存放遍历到的变量，所以当把\u0026v赋值到其他地方时，他的值一直是一样的。正确的做法是在遍历过程中用一个新变量存v的值，或者用index for i, v := range arr{ res = append(res, \u0026arr[i]) } // or for _, v := range arr{ temp := v res = append(res, \u0026temp) } ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:2:1","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"切片 ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:3:0","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"append返回新切片 调用方法中的append是复制操作，所以虽然传给fun4的m是个指针，但是append后的m是复制的，与原先传进来的m的地址不一样。这个时候在main中的打印m没有aaa。 所以要用func5这样，把m也返回回去。 func main() { m := make([]string, 0) func4(m) fmt.Println(m) //[] m = func5(m) fmt.Println(m) //[aaa] } func func4(m []string) { m = append(m, []string{\"aaa\"}...) return } func func5(m []string) []string { m = append(m, []string{\"aaa\"}...) return m } ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:3:1","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"append其他切片 背景是在做leetcode时遇到一个子集问题，在BackT方法是遍历+递归获取当前数路径path，并将path append到结果切片res中。在这个append时候，如果直接使用res = append(res, path)会导致最终结果错误。因为path其实是个指针，且后续path的值会修改，如果这里直接append path， 后面如果path被修改的话，res里原来的值也会被同步修改。 所以需要用一个新的切片复制原path，在append到res中。或者也可以直接res = append(res, append([]int{}, path...))。 var res [][]int func subsets(nums []int) [][]int { res = make([][]int, 0) path := make([]int, 0) BackT(path, nums) return res } func BackT(path, chos []int) { // 对于二叉树每个节点，要弄清楚，一进入这个节点需要做什么 tmp := make([]int, len(path)) copy(tmp, path) res = append(res, tmp) if len(chos) == 0 {// 这个判断可以不用，因为下面的循环不会执行就直接返回 return } for i, v := range chos { path = append(path, v) chos2 := chos[i+1:] BackT(path, chos2) path = path[:len(path) - 1] } } ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:3:2","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"结构体 ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:4:0","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"结构体初始化 对于引用类型变量(slice，map，channe)，使用时需要分配内存空间(make函数)，否则值没办法存。而对于在Go语言中对于引用类型的变量，我们在使用的时候不仅要声明它，还要为它分配内存空间，否则我们的值就没办法存储。而对于值类型的声明不需要分配内存空间，是因为它们在声明的时候已经默认分配好了内存空间 var tx *gorm.DB getConn(tx) func getConn(tx *gorm.DB) *gorm.DB{ if tx == nil { return gmysql.Master(constants.MasterID).Table(\"admin_group_tab\").Debug() } return tx } 可以走到tx==nil 但是 getConn(\u0026gorm.DB{})不能 ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:4:1","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"锁 ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:5:0","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"乐观锁 用乐观锁需要关注affect rows，保证本次用乐观锁的改动是当前进程改的，不是其他进程改动。 ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:5:1","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"编译 CGO_ENABLED=0 GOOS=linux go build -mod=vendor -a -installsuffix cgo -o main main.go 编译时如果报错什么undefined，可以看对应的包是否有引入C的包，因为CGO_ENABLED=0为静态编译，但是引入的包C会有外部动态依赖，所以带导致编译不成功。具体可以参考：https://promacanthus.netlify.app/experience/golang/01-编译的坑/ ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:6:0","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"奇怪报错 ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:7:0","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"Converting circular structure to JSON {\"statusCode\":500,\"error\":\"Internal Server Error\",\"message\":\"Converting circular structure to JSON\\\\n --\u003e starting at object with constructor 'ClientRequest'\\\\n | property 'socket' -\u003e object with constructor 'Socket'\\\\n --- property '_httpMessage' closes the circle\"}% 这种大概率是网关转换报错。之前这个场景是配置文件没配redis，导致获取redis的client为空，然后用rc.Del时空指针panic了，然后admin网关处理空返回处理报错。 func DelInfoFromCache(key string) (deleted int64, err error) { rc := lobster.GetClient() cmd := rc.Del(key) deleted, err = cmd.Result() if err != nil { log.Error(\"DelInfoFromCache err|err=%v\", err) } return } ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:7:1","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["go"],"content":"inner connection failed from new connection. 重启对应的两个pod。可能是pod所属的node网络有点问题。 ","date":"2023-02-09","objectID":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/:7:2","tags":["go"],"title":"遇到的坑们","uri":"/posts/go/%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E4%BB%AC/"},{"categories":["system"],"content":"package和go_package 对于一个的go项目，包管理一般需要go module管理，同理对于pb包也是。所以需要在pb项目先go mod init pb项目名，然后再定义proto文件。 在定义时有package和option go_package两个属性，俩者的区别大致为： 假设B定义的package是bPB, 定义的option_go的package是pbGO。则proto文件A引用proto文件B定义的messag时，需要加B定义的bPB前缀。其他go文件需要引用B生成的Go文件内容时，需要加前缀pbGO。详细如下： package属于 proto 文件自身的范围定义，与生成的 go 代码无关。这个 proto 的 package 的存在是为了避免当引用其他 proto 文件的message时导致的文件内的命名冲突，可以理解为message的前缀。所以，在引用非本包(这个包是指proto文件声明package，而不是goland目录的包)的 message 时，需要加 package 前缀。所以假设两个文件在同一包，但是package定义的名字不同，则引用时也等同于非本包导入。 而 option go_package 的声明就和生成的 go 代码相关了，它定义了生成的 go 文件所属包的完整包名，所谓完整，是指相对于该项目的完整的包路径，应以项目的 Module Name 为前缀。假设文件B的proto文件中没有指定好这个，文件A引用了文件B的message X，在proto文件中可以通过第一个的package引用，不会报错，但是文件A生成的go文件会引用到文件A自己的X，找不到导致报错。 import时填的包名就是gloand文件目录路径。 举个栗子：包结构如下，首先在blog.proto文件定义不同的package和go_package，查看生成的go文件包名。然后在user.proto文件中引用blog.proto文件，看需要怎么引用。 syntax = \"proto3\"; option go_package=\"github.com/ricky-zhf/go-web/common/pb/blog;blogGo\"; //这里如果直接用./blog，后续依赖该文件的user.proto所生成go文件会报错，找不到依赖的message。 package blogProto; service BlogService { rpc GetBlog (GetBlogRequest) returns (GetBlogResponse) {} } message GetBlogRequest { string title = 1; } message GetBlogResponse { repeated Blog blog = 1; } message Blog { string author = 1; string title = 2; string content = 3; } 生成的go文件如下，可以看到go文件的包名是blogGo 假设需要在user.proto文件中引用blog.proto文件： syntax = \"proto3\"; option go_package=\"github.com/ricky-zhf/go-web/common/pb/user\"; package user; import \"pb/blog/blog.proto\"; //import时填的包名就是gloand文件目录路径。 service UserService { rpc GetAllUserBlogs (GetAllUserBlogsRequest) returns (GetAllUserBlogsResponse) {} } message GetAllUserBlogsRequest { string user_id = 1; } message GetAllUserBlogsResponse { repeated blogProto.Blog blog = 1; //引用blog目录下，proto定义的package name为blogProt的message Blog } 如果是在其他go文件中引用blog定义的Blog message则如下图，可以看到引入包的路径就是正常路径，但是使用时要用 ","date":"2023-02-03","objectID":"/posts/system/grpc%E7%9A%84package/:1:0","tags":["grpc"],"title":"package和go_package","uri":"/posts/system/grpc%E7%9A%84package/"},{"categories":["middleware"],"content":"概念 Nginx是一款轻量级的Web服务器、代理服务器，由于它的内存占用少，启动极快，高并发能力强，在互联网项目中广泛应用。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:1:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"正反向代理 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:2:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"正向代理 由于防火墙的原因，我们并不能直接访问谷歌，那么我们可以借助VPN来实现，这就是一个简单的正向代理的例子。这里你能够发现，正向代理“代理”的是客户端，而且客户端是知道目标的，而目标是不知道客户端是通过VPN访问的。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:2:1","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"反向代理 当我们在外网访问百度的时候，其实会进行一个转发，代理到内网去，这就是所谓的反向代理，即反向代理“代理”的是服务器端，而且这一个过程对于客户端而言是透明的。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:2:2","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"负载均衡 负载均衡有四层负载均衡和七层负载均衡 四层工作在OSI第四层，也就是传输层；七层工作在最高层，也就是应用层。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:3:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"四层负载均衡 四层负载均衡就是使用IP加端口的方式进行路由转发，由于其工作在第四层，所以不会查看报文的实际信息。 四层负载均衡具体实现方式为：通过报文中的IP地址和端口，再加上负载均衡设备所采用的负载均衡算法，最终确定选择后端哪台下游服务器。 以TCP为例，客户端向负载均衡服务器发送SYN请求建立第一次连接，通过配置的负载均衡算法选择一台后端服务器，并且将报文中的IP地址信息修改为后台服务器的IP地址信息，因此TCP三次握手连接是与后端服务器直接建立起来的。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:3:1","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"七层负载均衡 七层负载均衡一般是基于请求URL地址的方式进行代理转发。由于它工作在第七层，所以在接到客户端的流量以后，还需要一个完整的TCP/IP协议栈。七层负载均衡会与客户端建立一条完整的连接并将应用层的请求流量解析出来，再按照调度算法选择一个应用服务器，并与应用服务器建立另外一条连接将请求发送过去，因此七层负载均衡的主要工作就是代理。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:3:2","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"进程模型 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:4:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"概念 nginx在启动后，在unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。当然nginx也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是nginx的默认方式。nginx采用多进程的方式有诸多好处，所以我就主要讲解nginx的多进程模式吧。 nginx在启动后，会有一个master进程和多个worker进程。 master进程主要用来管理worker进程，包含：读取并验证config文件，接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。 而基本的网络事件，则是放在worker进程中来处理了。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。 多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。nginx的进程模型，可以由下图来表示： ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:4:1","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"优点 对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。 采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快启动新的worker进程。 如果worker进程的异常退出，肯定是程序有bug了，异常退出，会导致当前worker上的所有请求失败，不过不会影响到所有请求，所以降低了风险。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:4:2","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"事件处理过程 异步非阻塞的事件处理机制，具体到系统调用就是像select/poll/epoll/kqueue这样的系统调用。它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。 解析配置文件，得到需要监听的端口号和IP。然后在Nginx的Master进程里面初始化这个监控的socket（创建socket，设置addr，reuse等选项，绑定指定IP及端口号，在监听）。 fork多个子进程：每个 worker 进程都是从 master进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket（listenfd：监听套接字，listen file descriptor） 之后，然后再 fork 出多个 worker 进程。 所有worker进程的listenfd在新连接到来时变为可读的，为保证只有一个进程处理该连接，所有woker进程在注册listenfd读事件前需要竞争accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。 子进程进程accept新的连接。此时，客户端可以向nginx发送连接了。当三次握手建立完成，某个子进程accept成功，得到这个刚建好的socket，然后对连接进行封装，及ngx_connection_t结构体 设置读写时间处理函数，并添加读写时间来与客户端进行数据的交换 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:5:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"负载均衡 轮询：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 哈希：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 共享的问题。当然，实际场景下，一般不考虑使用 ip_hash 解决 session 共享。 最少连接：下一个请求将被分派到活动连接数量最少的服务器 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:6:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"热部署 所谓热部署，就是配置文件nginx.conf修改后，不需要stop Nginx，不需要中断请求，就能让配置文件生效！（nginx -s reload 重新加载/nginx -t检查配置/nginx -s stop） 通过上文我们已经知道worker进程负责处理具体的请求，那么如果想达到热部署的效果，可以想象： 方案一： 修改配置文件nginx.conf后，主进程master负责推送给woker进程更新配置信息，woker进程收到信息后，更新进程内部的线程信息。（有点valatile的味道） 方案二： 修改配置文件nginx.conf后，重新生成新的worker进程，当然会以新的配置进行处理请求，而且新的请求必须都交给新的worker进程，至于老的worker进程，等把那些以前的请求处理完毕后，kill掉即可。 Nginx采用的就是方案二来达到热部署的。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:7:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"其他功能 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:8:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"动静分离 Nginx能够提高速度的其中一个特性就是：动静分离，就是把静态资源放到Nginx上(追求高效可以用CDN)，由Nginx管理，动态请求转发给后端。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:8:1","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"黑名单 Nginx可以进行IP访问控制，有些电商平台，就可以在Nginx这一层，做一下处理，内置一个黑名单模块，那么就不必等请求通过Nginx达到后端在进行拦截，而是直接在Nginx这一层就处理掉。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:8:2","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"缓存 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:8:3","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"高并发 异步非阻塞工作方式。不使用原先BIO，即一个进程处理一个request的方式。而是每进来一个request，会有一个worker进程去处理，但不是全程处理。当处理到可能发生阻塞的地方（比如后端服务器转发request并等待请求返回），这个worker会在发送完请求后注册一个事件：如果当前请求返回了，通知并接着干。然后它就可以处理其他请求即非阻塞。客户端也无需等待，可以做其他的事情，即异步。这就是为什么说，Nginx 基于事件模型。 Nginx采用了Linux的epoll模型，epoll模型基于事件驱动机制，它可以监控多个事件是否准备完毕，如果OK，那么放入epoll队列中，这个过程是异步的。worker只需要从epoll队列循环处理即可。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:9:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"高可用 Keepalived+Nginx实现高可用。 Keepalived是一个高可用解决方案，主要是用来防止服务器单点发生故障，可以通过和Nginx配合来实现Web服务的高可用。（其实，Keepalived不仅仅可以和Nginx配合，还可以和很多其他服务配合） Keepalived+Nginx实现高可用的思路： 第一：请求不要直接打到Nginx上，应该先通过Keepalived（这就是所谓虚拟IP，VIP） 第二：Keepalived应该能监控Nginx的生命状态（提供一个用户自定义的脚本，定期检查Nginx进程状态，进行权重变化,，从而实现Nginx故障切换） ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:10:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"配置 https://blog.csdn.net/zxd1435513775/article/details/102508463 主配置文件一般处于/etc/nginx/nginx.conf，然后会引用conf.d中的所有conf后缀文件，这里面一般就是自己配置的。静态文件如index.html等一般在/usr/share/nginx/html中 我们使用 nginx 的 http 服务，在配置文件 nginx.conf 中的 http 区域内，配置多个 server ，每一个 server 对应这一个虚拟主机或者域名。 ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:11:0","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"nginx.conf user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #定义日志格式 代号为main access_log /var/log/nginx/access.log main;#日志保存地址 格式代码 main sendfile on; #高效传输文件的模式 一定要开启 #tcp_nopush on; keepalive_timeout 65; #客户端服务端请求超时时间 #gzip on; include /etc/nginx/conf.d/*.conf; } ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:11:1","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["middleware"],"content":"conf文件 server { listen 80; #ipv4 listen [::]:80; #ipv6 server_name localhost; #匹配域名同一个server_name需要放在同一个server下 location / { root /usr/share/nginx/html; index rev.html; proxy_pass http://router_server:8000; #反向代理 localhost:80的流量代理到router_server:8000 } location /api { proxy_pass http://router_server_upstream:8000; } #access_log /var/log/nginx/host.access.log main; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } 负载均衡配置 # 负载均衡：设置domain 8000和8001是本地用起的两个服务 upstream domain { server localhost:8000; server localhost:8001; } server { listen 8080; server_name localhost; location / { # root html; # Nginx默认值 # index index.html index.htm; proxy_pass http://domain; # 负载均衡配置，请求会被平均分配到8000和8001端口 proxy_set_header Host $host:$server_port; } } ","date":"2023-02-02","objectID":"/posts/middleware/nginx/:11:2","tags":["nginx"],"title":"nginx学习","uri":"/posts/middleware/nginx/"},{"categories":["system"],"content":"Paxos Paxos算法是一种经典的分布式一致性算法，它通过一系列投票过程来保证数据的一致性。Paxos算法可以解决分布式系统中的状态机复制问题，即如何将一个状态机的状态复制到多个节点上，使得多个节点上的状态保持一致。 Paxos算法的基本思想是，将一个值的提案分为三个阶段： 提议阶段（Prepare Phase）：提议者向其他节点发送编号为n的提议请求，其中n是一个递增的序列号。 承诺阶段（Promise Phase）：如果一个节点收到了一个编号为n的提议请求，它会比较提议的编号n与自己保存的最大编号m的大小，如果n\u003em，则节点会回复一个承诺，承诺不再接受编号小于n的提议请求，并将自己接受的最大编号作为回复。 决策阶段（Accept Phase）：如果一个节点收到了大多数节点的承诺回复，它就可以向所有节点发送一个决策请求，请求将值v与编号n绑定，形成一个提案，并将该提案提交给其他节点。 如果一个节点接受了某个提议，它就会向其他节点广播一个accept请求，该请求包含编号n和值v。其他节点如果接受了该请求，就会将该值v记录到自己的状态中。 Paxos算法的核心思想是通过多轮投票来达成一致性。如果某个节点不能在提议阶段或者承诺阶段达成一致，那么该节点就不会参与后续的决策阶段。通过这样的方式，Paxos算法可以保证多个节点上的状态保持一致。 尽管Paxos算法比较复杂，但是它在实际应用中得到了广泛的应用，例如Google的Chubby分布式锁服务就是基于Paxos算法实现的。 ","date":"2023-01-28","objectID":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/:1:0","tags":["system"],"title":"分布式一致性算法","uri":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"},{"categories":["system"],"content":"Raft Raft算法是一种分布式一致性算法，它通过领导人选举、日志复制和安全性机制来确保分布式系统中的数据一致性。 ","date":"2023-01-28","objectID":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/:2:0","tags":["system"],"title":"分布式一致性算法","uri":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"},{"categories":["system"],"content":"领导人选举 在Raft算法中，节点分为三种角色：领导人、跟随者和候选人。领导人负责处理客户端的请求，并将结果返回给客户端。如果领导人失效或无法正常工作，那么需要选举一个新的领导人。且Raft算法是一种强领导者的共识算法，也就是说在一个集群中，有且仅有一个Leader节点负责处理客户端的请求和管理其他节点的日志复制。Raft算法会将时间划分为不定长度的任期（Terms），每个任期都有一个唯一的编号。每个节点都会记录当前所处的任期和当前认可的Leader。 在正常情况下，所有节点都是跟随者角色。当一个节点发现自己无法与其他节点进行通信时，它就会自我宣布为候选人，并开始发起选举。候选人向其他节点发送投票请求，并等待其他节点的回复。如果候选人在一定时间内没有得到足够的选票，那么它就会放弃当前的任期，转化为跟随者角色。 如果一个节点接收到了候选人的投票请求，它会比较自己的当前任期号和候选人的任期号。如果候选人的任期号比自己的大，则节点会转化为跟随者，并将自己的任期号更新为候选人的任期号。节点还会投票给候选人，并重置选举计时器。如果候选人得到了大多数节点的支持，那么它就会成为新的领导人。 ","date":"2023-01-28","objectID":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/:2:1","tags":["system"],"title":"分布式一致性算法","uri":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"},{"categories":["system"],"content":"日志复制 Raft算法通过日志复制机制来确保节点之间的数据一致性。领导人负责将客户端的请求转化为日志条目，并将日志条目按照先后顺序发送给所有跟随者。跟随者在接收到日志条目后，将其存储在本地日志中，并向领导人发送确认信息。一旦领导人收到了大多数节点的确认信息，就可以将该日志条目提交到状态机中执行。 ","date":"2023-01-28","objectID":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/:2:2","tags":["system"],"title":"分布式一致性算法","uri":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"},{"categories":["system"],"content":"安全性 Raft算法还通过一系列机制来确保分布式系统的安全性，包括： 节点之间的通信必须经过认证和加密如ssl/tsl，以防止网络攻击和数据篡改。 如果多个节点同时发起选举，那么它们可能会形成“分裂投票”情况。为了防止这种情况发生，Raft算法会随机处理，以使选举过程更具随机性，减少选举的冲突。 领导人必须定期向跟随者发送心跳信号，以保持与跟随者的通信。如果跟随者在一定时间内没有收到心跳信号，那么它就会认为领导人失效，并开始发起新一轮选举。 如果某个日志条目在某个任期被提交，则它不能被覆盖；如果某个日志条目包含了一个新任期的值，则所有之前的日志条目都必须被提交。 ","date":"2023-01-28","objectID":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/:2:3","tags":["system"],"title":"分布式一致性算法","uri":"/posts/system/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"},{"categories":["uu"],"content":"u ","date":"2023-01-27","objectID":"/posts/uu/uu_picture/:0:0","tags":["uu"],"title":"u","uri":"/posts/uu/uu_picture/"},{"categories":["go"],"content":"二叉树 二叉树基本都是要用到递归，其思维模式分为两类： 遍历递归：是否可以通过遍历一遍二叉树得到答案。如果可以，用一个traverse函数配合外部变量来实现，这叫遍历的思维模式。即先操作当且节点，操作完后去操作左子树，再操作右子树，相当于前序遍历。这种思路对应回溯算法的思想； 分解递归：是否可以定义一个递归函数，通过子问题(子数)的答案推到出原问题的答案。如果可以，下处这个递归函数的定义，并充分利用这个函数的返回值。即当前节点的为题可以通过左子树和右子树的解来 获得，所以需要先操作左子树、再操作右子树、再计算当前节点的的答案，相当于后续遍历。这种思路对应动态规划的核心框架； 无论用哪个，都需要考虑两个问题： 如果单独抽出一个二叉树节点，他需要做什么事情？ 需要在什么时候做？ ","date":"2023-01-14","objectID":"/posts/go/go%E7%AE%97%E6%B3%95/:1:0","tags":["go"],"title":"go算法","uri":"/posts/go/go%E7%AE%97%E6%B3%95/"},{"categories":["go"],"content":"前中后序遍历 前序位置的代码在刚刚进入一个二叉树节点的时候执行； 后序位置的代码在将要离开一个二叉树节点的时候执行； 中序位置的代码在一个二叉树节点左子树都遍历完，即将开始遍历右子树的时候执行。 比如「 二叉树的最大深度」问题。如果使用遍历解法，那就需要先处理当前节点的，判断其深度，然后分别遍历左右节点: var depth int var maxDepthNum int func maxDepth(root *TreeNode) int { traverse(root) fmt.Println(maxDepthNum) return maxDepthNum } func traverse(root *TreeNode) { if root == nil { return } depth++ if root.Left == nil \u0026\u0026 root.Right == nil { maxDepthNum = max(maxDepthNum, depth) } traverse(root.Left) traverse(root.Right) depth-- } func max(x, y int) int { if x \u003e y { return x } return y } 如果使用分解递归，那就是当前节点的深度等于左右子树两个深度更大的那个，加上自己的1。所以需要先递归，找到左右子树的最大深度，然后再处理当前节点的结果。 func maxDepth(root *TreeNode) int { if root == nil { return 0 } x := maxDepth(root.Left) y := maxDepth(root.Right) return max(x, y) + 1 } func max(x, y int) int { if x \u003e y { return x } return y } ","date":"2023-01-14","objectID":"/posts/go/go%E7%AE%97%E6%B3%95/:1:1","tags":["go"],"title":"go算法","uri":"/posts/go/go%E7%AE%97%E6%B3%95/"},{"categories":["go"],"content":"后序遍历的特殊 当解题发现需要获取左右子树的信息时，就需要考虑后续遍历的操作。 前序位置的代码执行是自顶向下的，而后序位置的代码执行是自底向上的，这也意味着前序位置的代码只能获取父节点传递过来的信息，对于其子节点的信息时不知道的。相反，后续遍历时，由于自底向上，所以不仅知道父节点的信息，也知道子节点的信息。举个例子 ","date":"2023-01-14","objectID":"/posts/go/go%E7%AE%97%E6%B3%95/:1:2","tags":["go"],"title":"go算法","uri":"/posts/go/go%E7%AE%97%E6%B3%95/"},{"categories":["go"],"content":"DFS和BFS DFS（深度优先搜索）和 BFS（广度优先搜索）。如果我们使用 DFS/BFS 只是为了遍历一棵树、一张图上的所有结点的话，那么 DFS 和 BFS 的能力没什么差别，我们当然更倾向于更方便写、空间复杂度更低的 DFS 遍历。不过，某些使用场景是 DFS 做不到的，只能使用 BFS 遍历。这就是本文要介绍的两个场景：层序遍历、最短路径。 先看下DFS： func dfs(root *TreeNode) { if (root == null) { return; } dfs(root.left); dfs(root.right); } BFS 遍历使用队列数据结构： void bfs(TreeNode root) { Queue\u003cTreeNode\u003e queue = new ArrayDeque\u003c\u003e(); queue.add(root); while (!queue.isEmpty()) { TreeNode node = queue.poll(); // Java 的 pop 写作 poll() if (node.left != null) { queue.add(node.left); } if (node.right != null) { queue.add(node.right); } } } 二叉树的层次遍历 这里用两个队列，一个存最终的结果res，一个存当前需要遍历的节点nodes。 在遍历到每个节点时，先创建一个队列levelQueue用于维护每一层的节点，然后遍历nodes，将里面里面的节点都取出来放进levelQueue，与此同时，将每个节点的左右节点分别nodes。最后将levelQueue拼接到res后，然后nodes删除遍历过的节点即可。 func levelOrder(root *TreeNode) [][]int { if root == nil { return nil } res := make([][]int, 0) //结果队列 nodes := make([]*TreeNode, 0) // 遍历队列 nodes = append(nodes, root) for len(nodes) != 0 { levelQueue := make([]int, 0)//每一层的队列 levelLen := len(nodes) //len需要先定，因为for循环里会增加 for i:= 0; i \u003c levelLen; i++ { levelQueue = append(levelQueue, nodes[i].Val) if nodes[i].Left != nil { nodes = append(nodes, nodes[i].Left) } if nodes[i].Right != nil { nodes = append(nodes, nodes[i].Right) } } res = append(res, levelQueue) nodes = nodes[levelLen:] } return res } 或者使用深度遍历 func levelOrder(root *TreeNode) [][]int { res := make([][]int, 0) depth := 0 var t func(root *TreeNode) t = func(root *TreeNode) { if root == nil { return } if depth \u003e= len(res) { res = append(res, []int{}) } res[depth] = append(res[depth], root.Val) depth++ t(root.Left) t(root.Right) depth-- } t(root) return res } ","date":"2023-01-14","objectID":"/posts/go/go%E7%AE%97%E6%B3%95/:1:3","tags":["go"],"title":"go算法","uri":"/posts/go/go%E7%AE%97%E6%B3%95/"},{"categories":["go"],"content":"LRU /* 1. 实现一个简易的LRU（最近最少使用）缓存。根据数据的历史访问记录来进行淘汰数据，“如果数据最近被访问过，那么将来被访问的几率也更高”。 2. 使用双向链表，链表节点中包含cache的key和value，此外还有前后指针 3. 为了加快判断命中效率，使用map缓存key:*node 4. 最主要两个方法为put和get： 4.1 put命中将节点移到链表头； 4.2 put未命中，根据链表节点数是否超过限制来判断是否需要删除链表尾节点，然后在链表头插入节点； 4.3 get命中，同4.1; 4.4 get未命中，返回错误。 */ type Node struct { Key, Value int Pre, Next *Node } type LRUCache struct { Cap int Len int CacheMap map[int]*Node head, tail *Node } func InitLRU(cap int) *LRUCache { l := \u0026LRUCache{ Cap: cap, Len: 0, CacheMap: map[int]*Node{}, head: \u0026Node{}, tail: \u0026Node{}, } l.head.Next = l.tail l.tail.Pre = l.head return l } // 根据key获取 value 以及并更新链表 func (l *LRUCache) Get(key int) int { if v, ok := l.CacheMap[key]; ok { l.moveToHead(v) return v.Value } return -1 } func (l *LRUCache) Put(key, value int) { if v, ok := l.CacheMap[key]; ok { v.Value = value l.moveToHead(v) return } //不存在 node := \u0026Node{key, value, nil, nil} for l.Len \u003e= l.Cap { //删除尾节点 l.deleteTail() } l.insertToHead(node) } func (l *LRUCache) deleteTail() { temp := l.tail.Pre temp.Pre.Next = l.tail l.tail.Pre = temp.Pre temp.Pre = nil temp.Next = nil l.Len-- delete(l.CacheMap, l.tail.Key) } // 将访问到的节点更新到链表头 func (l *LRUCache) moveToHead(node *Node) { node.Pre.Next = node.Next node.Next.Pre = node.Pre temp := l.head.Next l.head.Next = node node.Pre = l.head node.Next = temp temp.Pre = node } // 将创建的节点插入链表头 func (l *LRUCache) insertToHead(node *Node) { temp := l.head.Next l.head.Next = node node.Pre = l.head node.Next = temp temp.Pre = node l.Len++ l.CacheMap[node.Key] = node } ","date":"2023-01-14","objectID":"/posts/go/go%E7%AE%97%E6%B3%95/:2:0","tags":["go"],"title":"go算法","uri":"/posts/go/go%E7%AE%97%E6%B3%95/"},{"categories":["go"],"content":"堆 堆的内容涉及两个部分： 建堆，或者维护堆； 堆排序。 建堆的关键属性就是，父节点的值大于子节点的值， 所以父节点的值自然也大于左右子树所有节点的值，所以根节点就是所有元素中最大的。==但是，堆不能保证左节点大于右节点，所以堆的层次遍历并不能保证顺序==。 而堆排序则是使用堆的性质对一组元素进行排序。因为顶点节点是最大的节点，所以可以直接将其与堆最后一个元素交换(使最后一个位置的是最大元素)。然后对0到(n-1)位置的元素再进行维护堆的操作，就又能找到第二大的元素，再交换到n-1的位置，以此来排序。 ","date":"2023-01-14","objectID":"/posts/go/go%E7%AE%97%E6%B3%95/:3:0","tags":["go"],"title":"go算法","uri":"/posts/go/go%E7%AE%97%E6%B3%95/"},{"categories":["go"],"content":"第k大元素 构建大顶堆 func findKthLargest(nums []int, k int) int { //建堆 buildHeap(nums, 0, len(nums)) //这里需要一个变量存储len值，因为随着堆顶元素和最后一个元素交换，长度需要减1。 heapLen := len(nums) // 这里的可以发现和buildHeap方法很像，buildHeap是从第一个非叶子结点开始调整堆结构。 // 这里是在从堆低交换元素后，从堆顶元素开始调整堆结构 for i := len(nums) - 1; i \u003e= 0; i-- { nums[0], nums[i] = nums[i], nums[0] heapLen-- heapify(nums, 0, heapLen) } // 第k大，就是第n-k+1小，就是n-k的位置上的元素 return nums[len(nums) - k] } func buildHeap(heap []int, x, length int) { length = len(heap) for i := length / 2 - 1; i \u003e=0; i-- { //从第一个非叶子结点(length/2-1)开始，从下至上，从右至左地调整结构 heapify(heap, i, length) } } func heapify(heap []int, x, length int) { // 找到当前节点和其左右子节点的最大值 large := x if x * 2 + 1 \u003c length \u0026\u0026 heap[x * 2 + 1] \u003e heap[large] {//如果需要构建小顶堆，这里符号变下，其他都不用变 large = x * 2 + 1 } if x * 2 + 2 \u003c length \u0026\u0026 heap[x * 2 + 2] \u003e heap[large] {//如果需要构建小顶堆，这里符号变下，其他都不用变 large = x * 2 + 2 } if large != x { heap[x], heap[large] = heap[large], heap[x] // 继续比较其父节点 heapify(heap, large, length) } } ","date":"2023-01-14","objectID":"/posts/go/go%E7%AE%97%E6%B3%95/:3:1","tags":["go"],"title":"go算法","uri":"/posts/go/go%E7%AE%97%E6%B3%95/"},{"categories":["go"],"content":"Container包 type IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(x, y int) bool { return h[x] \u003e h[y] }//这里大于就是大顶堆，小于就是小顶堆 func (h IntHeap) Swap(x, y int) { h[x], h[y] = h[y], h[x] } func (h *IntHeap) Push(x interface{}) { *h = append(*h, x.(int)) } func (h *IntHeap) Pop() interface{} { x := (*h)[len(*h)-1] *h = (*h)[:len(*h)-1] return x } func main() { h := \u0026IntHeap{1, 3, 99, 2, 7} heap.Init(h) heap.Push(h, 10) fmt.Println(\"max\", (*h)[0])//max 99 for h.Len() \u003e 0 { fmt.Println(heap.Pop(h))//99 10 7 3 2 1 } } ","date":"2023-01-14","objectID":"/posts/go/go%E7%AE%97%E6%B3%95/:3:2","tags":["go"],"title":"go算法","uri":"/posts/go/go%E7%AE%97%E6%B3%95/"},{"categories":["system"],"content":"服务注册 如：apc-id-dev-services:pb.ItemServer-0711:10.12.252.5:7020 // KeepAlive 续租 发送心跳，表明服务正常 func (e *EtcdRegister) KeepAlive() (\u003c-chan *clientv3.LeaseKeepAliveResponse, error) { resChan, err := e.etcdClient.KeepAlive(e.ctx, e.leaseId) if err != nil { log.Println(\"keepAlive failed,error=\", resChan) return nil, err } return resChan, nil } // WatchLicense 监听续约 func (e *EtcdRegister) WatchLicense(eChan \u003c-chan *clientv3.LeaseKeepAliveResponse) { for { select { case \u003c-eChan: // 续约成功这里会输出eChan // log.Printf(\"watcher keepalive successfully|license:%+v \\n\", l) case \u003c-e.ctx.Done(): _ = e.Close() log.Println(\"watcher keepalive end...\") return } } } // Close 关闭EtcdRegister func (e *EtcdRegister) Close() error { e.cancel() log.Printf(\"etcd closeing...EtcdRegister=%+v\\n\", e) // 撤销租约 _, err := e.etcdClient.Revoke(e.ctx, e.leaseId) if err != nil { log.Println(\"etcd client revoke failed|err=\", err) } return e.etcdClient.Close() } func f(...) ... { c, err := KeepAlive(...) ... WatchLicense(c) } ","date":"2023-01-13","objectID":"/posts/system/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/:1:0","tags":["etcd"],"title":"服务注册与发现","uri":"/posts/system/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"categories":["system"],"content":"服务发现 package etcd import ( \"fmt\" \"go.etcd.io/etcd/api/v3/mvccpb\" clientv3 \"go.etcd.io/etcd/client/v3\" \"log\" \"strings\" ) /* 服务发现: - GetService获取etcd中前缀为serviceName的所有key,value - 随后逐个updateSvrMap到EtcdRegister中的svrInfoMap中 - 随后watchService方法监控etcd中前缀为serviceName是否变动，并更新到svrInfoMap中 */ func (e *EtcdRegister) DiscoverService() { // Client.KV 是一个 interface ，提供了关于 K-V 操作的所有方法. kv := clientv3.NewKV(e.etcdClient) resp, err := kv.Get(e.ctx, ETCDPrefix, clientv3.WithPrefix()) if err != nil { fmt.Printf(\"get kv from etcd failed|err=%v\\n\", err) } // update svrMap for _, k := range resp.Kvs { e.updateSvrMap(string(k.Key)) } // watch service change go e.watchService() } func (e *EtcdRegister) watchService() { watchChan := e.etcdClient.Watch(e.ctx, ETCDPrefix, clientv3.WithPrefix()) for watchResp := range watchChan { for _, event := range watchResp.Events { switch event.Type { case mvccpb.PUT: //PUT事件，目录下有了新key log.Println(\"watch service key changed|key=\", string(event.Kv.Key)) e.updateSvrMap(string(event.Kv.Key)) case mvccpb.DELETE: //DELETE事件，目录中有key被删掉(Lease过期，key 也会被删掉) log.Println(\"watch service key deleted|key=\", string(event.Kv.Key)) e.mutex.Lock() sli := splitKey(string(event.Kv.Key)) delete(e.svrInfoMap, sli[1]) e.mutex.Unlock() } log.Println(\"map=\", e.svrInfoMap) } } } func (e *EtcdRegister) updateSvrMap(s string) { //ETCDKEY-blog_server-192.168.0.1-9090 sli := splitKey(s) if len(sli) != 4 { log.Printf(\"something wrong in resolving kvs|key=%v\", s) return } e.mutex.Lock() serName := sli[1] serIp := sli[2] serPort := sli[3] if _, ok := e.svrInfoMap[serName]; ok { e.svrInfoMap[serName][serIp] = serPort } else { m := map[string]string{ serIp: serPort, } e.svrInfoMap[serName] = m } e.mutex.Unlock() } func splitKey(key string) []string { return strings.Split(key, \":\") } ","date":"2023-01-13","objectID":"/posts/system/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/:2:0","tags":["etcd"],"title":"服务注册与发现","uri":"/posts/system/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"categories":["book"],"content":"有意义的命名 ","date":"2023-01-11","objectID":"/posts/books/clean-code/:1:0","tags":["book"],"title":"clean code笔记","uri":"/posts/books/clean-code/"},{"categories":["book"],"content":"名副其实 保证某一块代码中所有的名字能通过名字知道其意义。 函数名 变量名 public List\u003cint[]\u003e getThem(){ List\u003cint[]\u003e list1 = new ArrayList\u003cint[]\u003e(); for(int[] x : theList) { if(x[0] \u003cmark\u003e 4) { list1.add(x) } } return list1; } 这段代码有很多模糊的地方。 theList是什么含义？ theList中0下标条目是什么含义？ 值4是什么含义？ 返回的list1是什么含义？ 假设这是一个扫雷游戏，theList是单元格列表，其中数据0下标条目的含义是该单元格的状态，为4表示该单元格已标记，最后返回的是已经被标记的单元格List。则对于以上问题可以依次解决： theList —— gameBoard； 对于单元格，应该抽象为一个对象，创建一个Cell类，状态作为对象的一个属性； 然后未该类写一个方法isFlagged来表示该单元格被标记为4； list1 —— flaggedCells 最后改进后的代码 public List\u003cint[]\u003e getFlaggedCells(){ List\u003cint[]\u003e flaggedCells = new ArrayList\u003cint[]\u003e(); for(Cell cell: gameBoard) { if(cell.isFalgged()) { flaggedCells.add(cell) } } return flaggedCells; } ","date":"2023-01-11","objectID":"/posts/books/clean-code/:1:1","tags":["book"],"title":"clean code笔记","uri":"/posts/books/clean-code/"},{"categories":["book"],"content":"误导与区分 起变量名避免CS的专有名词，如账号列表如果起名accountList，会让人误以为它是一个list类型(如果是可以这样起名)。 同时，多使用常量。 ","date":"2023-01-11","objectID":"/posts/books/clean-code/:1:2","tags":["book"],"title":"clean code笔记","uri":"/posts/books/clean-code/"},{"categories":["book"],"content":"函数 ","date":"2023-01-11","objectID":"/posts/books/clean-code/:2:0","tags":["book"],"title":"clean code笔记","uri":"/posts/books/clean-code/"},{"categories":["book"],"content":"抽象层级 每个函数应该是一个抽象层级。在实现代码或者阅读代码时需要按照向下原则。使用TO(要***)语句，程序就像是一系列TO+函数名的段落，每一段都描述当前的抽象层级，并引用下一抽象层级。 既要(to)更新订单状态我们先判断，发货成功，则要(to)调用处理发货成功的逻辑，发货失败，则调用处理发货失败的逻辑。 要(to)处理发货成功后的步骤，我们需要先更新订单，再添加延迟队列，再通知各个依赖放该单已发货成功。 要(to)通知各个依赖方，… 要(to)处理发货失败后的逻辑，… 同时各个函数要保证短小，每个函数只说一件事。对于if、while等条件语句，其内部的代码块一般建议一行。如果函数只是做了该函数名下同一抽象层的步骤，则函数只做了一件事。既函数要么做什么事，要么回答什么事 比如函数： public boolean set(String attribute, String value){ if(table.isExist(attribute)) { table.attribute = value; return true; } else { return false; } } if(set(\"userName\", \"uncleBob\"))... set函数的操作是先判断table中是否有attribute变量，如果有就覆盖为value，如果没有就返回false。但是如果读者只看if语句，则会误以为set成功返回true，失败返回false。一个set既获取信息，又修改信息。所以可以改成 public void set(String attribute, String value){ // 赋值 } public boolean isExist(String attribute){ // 判断是否存在 } if(isExist(\"userName\")){ set(\"userName\", \"uncleBob\") } ","date":"2023-01-11","objectID":"/posts/books/clean-code/:2:1","tags":["book"],"title":"clean code笔记","uri":"/posts/books/clean-code/"},{"categories":["book"],"content":"函数命名 不要怕长，越详细越好。根据函数名就能清楚的知道函数做了什么。 使用动词+关键字的模式，如assertEquals，就可以改进为assertExpectEqualsActual。 ","date":"2023-01-11","objectID":"/posts/books/clean-code/:2:2","tags":["book"],"title":"clean code笔记","uri":"/posts/books/clean-code/"},{"categories":["book"],"content":"函数参数 函数参数越少越好，最好是一到两个，最多不能超过三个。多参数函数需要考虑将有联系的参数封装成类。 单参数函数 单个入参主要有两种场景： 获取入参相关信息，如：boolean fileExists(“MyFile”) 修改入参相关状态，如：InputStream fileOpen(“MyFile”) 双参数函数 双参数也可以接受。某些必须情况下的确需要传递两个参数(如坐标)。但是其他场景下可以考虑将两个参数优化成一个参数。例如： writeField(outputStream, name) -\u003e将该方法作为outputStream的成员之一：outputStream.writeField(name) -\u003e把outputStream写成当前类的成员变量，从而无需再传递它。 输出参数 appendFooter(s) 这个函数很迷惑，是把什么东西添加到s后面还是把s添加到什么后面？普遍而言，应避免使用输出参数，如果函数必须要修改某种状态，可以修改所属对象的状态。如： s.appendFooter() ","date":"2023-01-11","objectID":"/posts/books/clean-code/:2:3","tags":["book"],"title":"clean code笔记","uri":"/posts/books/clean-code/"},{"categories":["book"],"content":"对象和数据结构 描述了对象与数据结构之间的关系，两者是对立的。 既使用面向对象的代码难以添加新函数，因为需要修改所有的类。 而面向数据结构的代码难以添加新的数据结构，因为必须修改所有的函数 。 ","date":"2023-01-11","objectID":"/posts/books/clean-code/:3:0","tags":["book"],"title":"clean code笔记","uri":"/posts/books/clean-code/"},{"categories":["go"],"content":"设计模式六大原则 开闭原则：一个软件实体，如类、模块、函数，在实现后应该封闭修改，但是支持扩展； 单一指责原则：一个类只做一件事，一个类应该只有一个引起它修改的原因； 里氏替换原则：子类应该可以完全替换父类。也就是说在使用继承时，只扩展新功能，而不要破坏父类原有的功能。 依赖导致原则：细节应该依赖于抽象，抽象不应该依赖于细节。把抽象层放在程序设计的最高层，并保持稳定，程序的细节变化由底层来完成。 迪米特法则：又名“最少知道原则”，一个类不应该知道自己操作的类的细节。换言之，只和朋友交流，不和朋友的朋友交流。 接口隔离原则：客户单不应依赖它不需要的接口。如果一个接口在实现时，部分方法由于冗余被客户端空实现，则应该将接口拆分，让实现类只依赖自己需要的接口方法。 ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:1:0","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"构建型模式 工厂方法模式 抽象工厂模式 单例模式 原型模式 剪造型模式 ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:1:1","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"工厂模式 日常编程中，如果需要某一个对象一般就直接new一个。但是每new一个对象相当于调用者多知道了一个类，增加了两者之间的联系，不利于程序解耦。其实构建过程可以封装起来，工厂模式便是用于封装对象的设计模式。 举个例子,直接 new 对象的方式相当于当我们需要一个苹果时,我们需要知道苹果的构造方法，需要一个梨子时需要知道梨子的构造方法。 ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:2:0","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"简单工厂模式 优化上面的方式可以实现一个水果工厂，我们告诉工厂需要什么种类的水果，工厂便将我们需要的水果制造出来给我们就可以了。 func main() { //创建一个工厂类 factory := new(FruitFactory) fruit := factory.generate(\"apple\") fruit.beEaten(\"sooo many apple\") fruit2 := factory.generate(\"pear\") fruit2.beEaten(\"sooo many pear\") } //工厂类 type FruitFactory struct {} //工厂类的一个方法：生产水果 func (f FruitFactory) generate(s string) Fruit { switch s { case \"apple\": return \u0026Apple{} //因为实现Fruit接口的是Apple指针，所以这里要返回指针。 case \"pear\": return \u0026Pear{} default: return nil } } //产品接口 - 定义了一个方法：被吃 type Fruit interface{ beEaten(s string) } //苹果 type Apple struct {} func (apple *Apple) beEaten(s string) { //do something to generate apple fmt.Println(\"eat\", s) } //梨 type Pear struct {} func (pear *Pear) beEaten(s string) { //do something to generate Pear fmt.Println(\"eat\", s) } 但是还是有很多弊端，一是需要生产的产品过多时，工厂类就会过于庞大。当多个水果的生产过程变化时，就都会需要修改generate方法，违背了单一指责原则。其次是需要生产新的产品时，必须在工厂类中添加新的分支。这也违背了开闭原则，既我们需要添加产品时，应该只需要添加新的类。 ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:2:1","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"抽象工厂 结论：每个产品有一个工厂接口（用于返回产品接口）和产品接口（用于定义产品的各种方法），使用时调用产品的工厂接口得到产品接口，然后直接使用该接口中的各种方法即可 每个产品类有其对应的产品工厂类(如苹果工厂类)，每个产品工厂类实现了工厂接口，抽象工厂接口中有一个生产产品的方法，该方法的返回值是一个产品接口。 这样，如果需要某样产品，只需要创建其工厂类，然后使用面向工厂接口使用其内部方法即可。 解决了上面两个弊端： 工厂类被拆分为各个产品的工厂类中，所以当某一个产品的生产方式修改时，只需要修改其对应的工厂类即可； 如果有新的产品，我们只需要新增产品类和对应的产品工厂类，然后实现两个接口即可。 func main() { factory := new(AppleFactory) fruit := factory.generateFruit() fruit.beEaten(\"apple\") factory := new(PearFactory) fruit := factory.generateFruit() fruit.beEaten(\"pear\") } //工厂接口 type FruitFactory interface { generateFruit() Fruit } //产品接口 type Fruit interface{ beEaten(s string) } //苹果 type Apple struct {} func (apple *Apple) beEaten(s string) { //do something to generate apple fmt.Println(\"eat\", s) } //苹果工厂类 type AppleFactory struct {} func (apple *AppleFactory) generateFruit() Fruit { return \u0026Apple{} } //梨 type Pear struct {} func (pear *Pear) beEaten(s string) { //do something to generate Pear fmt.Println(\"eat\", s) } func (apple *Pear) generateFruit() Fruit { return \u0026Pear{} } //梨子工厂类 type PearFactory struct {} func (apple *PearFactory) generateFruit(s string) Fruit { return \u0026Pear{} } ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:2:2","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"单例模式 单例模式非常常见,某个对象全局只需要一个实例时,就可以使用单例模式。 能够避免对象重复创建，节约空间并提升效率； 避免由于操作不同实例导致的逻辑错误； 且实现时有以下几个需要注意的点： 构造函数需要时private访问权限，这样才能够避免外部通过new创建实例； 需要考虑对象创建时的线程安全问题； 需要考虑是否支持延迟加载； 需要考虑getInstance()性能是否会被限制（是否加锁） ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:3:0","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"使用场景 如各种池，线程池，DB连接池，Http连接池等，这些池子的创建就可以使用单例，全局只允许创建一个该池子。 ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:3:1","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"饿汉式 变量在声明时便初始化。 type singleton struct {} //private - 初始化 var instance = \u0026singleton{} //public func GetInstance() *singleton { return instance } 可以看到，在instance变量声明时就初始化了，后续线程如果想使用则需要通过GetInstance方法获取。但是也因此有一个弊端，既这个单例不需要使用，它也会在类加载后立即创建出来，占用内存且增加了类初始化时间。就好比一个修理工在修理东西时先把所有的工具全部拿出来了，所以称之为饿汉式。 ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:3:2","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"懒汉式 声明一个空变量，需要使用时才初始化。 type singleton struct {} //private - 初始化空变量 var instance *singleton //public func GetInstance() *singleton { if instance \u003cmark\u003e nil { instance = \u0026singleton{} //非线程安全 } return instance } 懒汉式解决了饿汉式的弊端，只需要按需加载。 但是也有问题，既线程不安全，多线程情况下，进入GetInstance是都判断instance为空，则都会获取一个instance变量。 ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:3:3","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"双检索 既check-lock-check来保证线程安全的同时，也保证一定的效率。 func GetInstance() *singleton { if instance \u003cmark\u003e nil { // \u003c--不够完善.他并不是完全的原子性 mu.Lock() defer mu.Unlock() if instance \u003cmark\u003e nil { instance = \u0026singleton{} } } return instance } 因为编译器优化，但是没有实例保存的状态的原子性检查。全面的技术考虑，这并不是安美的。 ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:3:4","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["go"],"content":"sync包 sync/aumoic 使用sync/atomic 包，我们可以原子性的加载和设置标识指示是否已经初始化了我们的实例。 import \" sync \" import \" sync/atomic \" var initialized uint32 ... func GetInstance() *singleton { if atomic.LoadUInt32(\u0026initialized) \u003cmark\u003e 1 { //check return instance } mu.Lock()//lock defer mu.Unlock() if initialized \u003cmark\u003e 0 {//check instance = \u0026singleton{} atomic.StoreUint32( \u0026initialized, 1 ) } return instance } sync.once sync有一个once结构体，这个可以紧缺的只执行一次操作，其原理和上面方法一样，就是封装好了。其源码如下： // Once is an object that will perform exactly one action. type Once struct { m Mutex done uint32 } // Do calls the function f if and only if Do is being called for the // first time for this instance of Once. In other words, given // var once Once // if once.Do(f) is called multiple times , only the first call will invoke f, // even if f has a different value in each invocation. A new instance of // Once is required for each function to execute. // // Do is intended for initialization that must be run exactly once. Since f // is niladic, it may be necessary to use a function literal to capture the // arguments to a function to be invoked by Do: // config.once.Do(func() { config.init(filename) }) // // Because no call to Do returns until the one call to f returns, if f causes // Do to be called, it will deadlock. // // If f panics, Do considers it to have returned; future calls of Do return // without calling f. // func (o * Once) Do(f func()) { if atomic.LoadUint32(\u0026o.done ) \u003cmark\u003e 1 { // \u003c-- Check return } // Slow-path. omLock() // \u003c-- Lock defer omUnlock() if o.done \u003cmark\u003e 0 { // \u003c-- Check defer atomic.StoreUint32(\u0026o.done, 1 ) f() } } 则最终在go里使用线程安全的单例可以如下： type singleton struct { } var ( instance *singleton once sync.Once ) func GetInstance() *singleton { once.Do(func() { instance = \u0026singleton{} }) return instance } ","date":"2023-01-05","objectID":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/:3:5","tags":["设计模式"],"title":"设计模式","uri":"/posts/go/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"categories":["hugo"],"content":"前言 使用hugo+loveIt主题搭建的博客，优化也是在此基础上做的，其他工具和主题仅供参考。 本人主业并不是前端相关，所以如果有更好的办法欢迎讨论~ ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:1:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"lastmod显示与自动更新 ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:2:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"显示 默认主页不显示文章的更新时间，所以需要对该部分内容定制修改下。首先找到/themes/LoveIt/layouts/_default/summary.html，然后复制到/layouts/_default/summary.html，并将该文件中的如下内容： {{- with .Site.Params.dateFormat | default \"2006-01-02\" | .PublishDate.Format -}} \u0026nbsp;\u003cspan class=\"post-publish\"\u003e {{- printf `\u003ctime datetime=\"%v\"\u003e%v\u003c/time\u003e` . . | dict \"Date\" | T \"publishedOnDate\" | safeHTML -}} \u003c/span\u003e {{- end -}} 修改为： {{- with .Site.Params.dateFormat | default \"2006-01-02\" | .PublishDate.Format -}} \u0026nbsp;\u003cspan class=\"post-publish\"\u003e {{- printf `\u003ctime datetime=\"%v\"\u003e%v\u003c/time\u003e` . . | dict \"Date\" | T \"publishedOnDate\" | safeHTML -}}, \u003c/span\u003e {{- end -}} {{- with .Site.Params.dateFormat | default \"2006-01-02\" | .Lastmod.Format -}} \u0026nbsp;\u003cspan class=\"post-publish\"\u003e {{- printf `\u003ctime datetime=\"%v\"\u003e%v\u003c/time\u003e` . . | dict \"Date\" | T \"updatedOnDate\" | safeHTML -}}, \u003c/span\u003e {{- end -}} ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:2:1","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"自动更新 在hugo的配置文件config.toml中新增配置项： [frontmatter] lastmod = [\":fileModTime\", \"lastmod\"] 如果是yml文件则为： frontmatter: lastmod: [\":fileModTime\", \"lastmod\"] ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:2:2","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"typora文本高亮语法适配 目前typora(0.11版本)的高亮语法为==highlight==，但是typora中所见的高亮部分在博客中是无法被正常渲染的，如下图所示： 大致原因是其与传统的markdown高亮语法\u003cmark\u003ehighlight\u003c/mark\u003e不同导致。 既然这样就改用\u003cmark\u003e\u003c/mark\u003e标记来高亮文本内容，但是这样博客上还是无法正常渲染，还需要在config.toml中添加配置： [markup.goldmark.renderer] unsafe = true 到这基本上就解决问题了。 如果想偷懒的话可以用搜狗输入法的自定义短语来实现快捷输入\u003cmark\u003e\u003c/mark\u003e的效果。 此外，如果嫌定义两个快捷输入——\u003cmark\u003e和\u003c/mark\u003e麻烦的话，可以只定义一个\u003cmark\u003e，只不过这样虽然博客上能正常渲染，但typora中\u003cmark\u003e不会自动隐藏，比较丑，看个人选择了。 ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:3:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"标题修改 如果不喜欢原主题二级标题前的#或者其他标题前的|可以去掉该部分。 找到文件/themes/LoveIt/assets/css/_page/_single.scss，删除或者注释掉header-mark中的部分即可。 \u003e h6 { \u003e .header-mark::before { // content: \"|\"; margin-right: .3125rem; color: $single-link-color; [theme=dark] \u0026 { color: $single-link-color-dark; } } } \u003e h2 \u003e .header-mark::before { // content: \"#\"; } ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:4:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"标题背景 在_custom.cscc文件中添加： /* 标题 */ .page.single h2 { //背景图阴影 //box-shadow: rgb(95, 90, 75) 0px 0px 0px 1px, rgba(10, 10, 0, 0.5) 1px 1px 6px 1px; //文字 color: rgb(44, 43, 43); font-family: 微软雅黑, 宋体, 黑体, Arial; font-weight: bold; line-height: 1.5; //text-shadow: rgba(34, 34, 34, 0.594) 2px 3px; background: rgba(17, 192, 231, 0.608); border-radius: 3px; //圆角 border-width: initial; border-style: none; border-color: initial; border-image: initial; padding: 7px; margin: 18px 0px 18px -5px !important; } ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:5:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"标题自动编号 然后在layout/posts/single.html中(如果没有该文件需要从/themes/LoveIt/layout/posts/single.html拷贝)找到如下内容: \u003carticle class=\"page single\"\u003e {{- /* Title */ -}} \u003ch1 class=\"single-title animate__animated animate__flipInX\"\u003e{{ .Title | emojify }}\u003c/h1\u003e ... 修改为如下内容： {{- $autonumber := .Param \"autonumber\" | default true -}} \u003carticle class=\"page single\" {{- if eq $autonumber true -}} autonumber {{- end -}}\u003e {{- /* Title */ -}} \u003ch1 class=\"single-title animate__animated animate__flipInX\"\u003e{{ .Title | emojify }}\u003c/h1\u003e ... 这样配置是文章默认自动生成标题编号。如果某文章不需要该功能，则在md文件的yml中添加如下配置项即可: autonumber: false 然后在/assets/css/_custom.scss文件中(没有则新建)添加如下内容: h1 {counter-reset: h2} h2 {counter-reset: h3} h3 {counter-reset: h4} h4 {counter-reset: h5} article[autonumber] h2::before {counter-increment: h2; content: \"#\" counter(h2) \" \"} article[autonumber] h3::before {counter-increment: h3; content: \"#\" counter(h2) \".\" counter(h3) \" \"} article[autonumber] h4::before {counter-increment: h4; content: \"#\" counter(h2) \".\" counter(h3) \".\" counter(h4) \" \"} 后续因为标题带有#和|并不好看，参考标题修改删除这两个标签，但是这样就丢失了标题的超链接。 如果想添加标题超链接，可以修改为: h1 {counter-reset: h2} h2 {counter-reset: h3} h3 {counter-reset: h4} h4 {counter-reset: h5} article[autonumber] h2 \u003e a::before {counter-increment: h2; content: \"#\" counter(h2) \" \"} article[autonumber] h3 \u003e a::before {counter-increment: h3; content: \"#\" counter(h2) \".\" counter(h3) \" \"} article[autonumber] h4 \u003e a::before {counter-increment: h4; content: \"#\" counter(h2) \".\" counter(h3) \".\" counter(h4) \" \"} ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:6:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"目录自动编号 目录编号也有两种方案，均是从二级标题开始编号，如果需要从一级标题开始自行修改下即可。 ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:7:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"ordered 这种是自带的方案，在config文件中添加如下配置： [markup] [markup.tableOfContents] endLevel = 5 #编号结束级别 startLevel = 2 #编号开始级别 ordered = true #开启自动编号 但是这样子标题的编号不会带上上一级标题。如下: ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:7:1","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"js 在/static/js/custom.js(没有则新建)中添加如下内容: function toc(parent, prefex) { parent.children(\"ul\").each(function () { $ul = $(this); $ul.children(\"li\").each(function () { $li = $(this); listStr = prefex if ($li.children(\"a\").length \u003e 0) { if (listStr != \"\") { listStr += \".\" } listStr += ($li.index() + 1); $li.html(listStr + \" \" + $li.html()); toc($li, listStr) } else { toc($li, listStr) } }); }); } var $t = $(\"#TableOfContents\"); toc($t, \"\"); 这种办法各级标题编号都会带上上一级标题编号。 如果不喜欢目录编号后的|可以在themes/LoveIt/assets/css/_partial/_single/_toc.scss中找到如下内容： .toc-content { font-size: var(--toc-content-font-size); ul { text-indent: -0.85rem; padding-left: .8rem; list-style: none; a:first-child::before { content: \"|\"; font-weight: bolder; margin-right: .5rem; color: $single-link-color; [theme=dark] \u0026 { color: $single-link-color-dark; } } ul { padding-left: 1.5rem; } } 对:before中内容进行修改即可 ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:7:2","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"时间页显示最新5条 首先在config.toml中添加新的配置项： [params.section] lastUpdatedSize = 5 接着修改/layouts/_default/section.html(如果没有该文件需要从/themes/LoveIt/layouts/_default/section.html拷贝)，在文件{{- /* Paginate */ -}}上方插入如下代码: {{- /* Last Modified */ -}} {{- $lastUpdatedSize := .Site.Params.section.lastUpdatedSize -}} {{- if $lastUpdatedSize -}} {{- if .Pages -}} {{- $pages := .Pages.ByLastmod.Reverse -}} \u003ch3 class=\"group-title\"\u003e最近更新 \u003csup\u003e{{- $lastUpdatedSize -}}\u003c/sup\u003e\u003c/h3\u003e {{- range first $lastUpdatedSize $pages -}} \u003carticle class=\"archive-item\"\u003e \u003ca href=\"{{ .RelPermalink }}\" class=\"archive-item-link\"\u003e {{- .Title -}} \u003c/a\u003e \u003cspan class=\"archive-item-date\"\u003e {{- $.Site.Params.section.dateFormat | default \"01-02\" | .Date.Format -}} \u003c/span\u003e \u003c/article\u003e {{- end -}} {{- end -}} {{- end -}} 至此就算搞定了。 但是配置后发现最新更新文章的时间格式和其他时间格式不一样，强迫症看着有点难受。所以在配置文件中做如下修改: [params.section] ... # 日期格式修改为如下内容 dateFormat = \"2006-01-02\" 这样因为时间格式太长又会导致换行，所以还需要找到LoveIt/assets/css/_partial/_archive/_terms.scss文件中.archive-item-date 段落，注释掉width: 5em;即可 ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:8:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"百度收录 实现博客内容能够在百度中被查询到。 登录百度资源，选择 用户中心-\u003e站点管理-\u003e添加网站，然后添加网站域名。在第三步使用文件验证，将验证文件放到static文件夹下，如果直接通过域名:文件名能够访问，则ok。最后点击完成验证。 随后选择搜索服务-\u003e普通收录-\u003esitemap，然后输入域名:sitemap.xml。由于hugo会在public下自动生成sitemap文件，所以无需新增。但是如果config文件中没有配置需要添加下： # 网站地图配置 [sitemap] changefreq = \"weekly\" filename = \"sitemap.xml\" priority = 0.5 然后点击提交即可。 ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:9:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"百度统计 通过百度统计网点流量信息等内容。 首先需要注册下，登录百度统计网站，然后注册或者登录后，在使用设置-\u003e账户设置-\u003e网站列表中新增网站，输入自己的域名和其他相关内容完成添加。 随后点击获取代码，复制hm.src = \"https://hm.baidu.com/hm.js?后的数字内容，添加到下面配置项中的id属性。 在config文件中添加如下内容(可以只添加baidu部分)： # LoveIt 新增 | 0.2.0 网站分析配置 # Analytics config [params.analytics] enable = true #这里记得设置为true ... # 百度统计 [params.analytics.baidu] id = \"\" #输入上面复制的id 然后拷贝\\themes\\LoveIt\\layouts\\partials\\plugin\\analytics.html到\\layouts\\partials\\plugin\\analytics.html。 打开拷贝后的analytics.html文件，在Fathom Analytics的代码下面加上如下内容： {{- /* Baidu Analytics */ -}} {{- with $analytics.baidu.id -}} \u003cscript\u003e var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?{{ . }}\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); \u003c/script\u003e {{- end -}} 然后在百度统计网站的网站列表页点击代码检查即可检查是否正确配置。 成功后一般过5-20即可查看网站流量数据。 ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:10:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["hugo"],"content":"标题动一下特效 修改在layouts/taxonomy下的terms.html和layouts/_default的section.html两个文件，修改h2 class =后面的部分为如下内容： single-title animate__animated animate__pulse animate__faster ","date":"2023-01-04","objectID":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/:11:0","tags":["hugo","loveit"],"title":"功能优化","uri":"/posts/hugo/%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":null,"content":"… ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"}]